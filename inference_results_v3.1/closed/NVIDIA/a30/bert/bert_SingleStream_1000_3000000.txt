$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
make[1]: Entering directory '/work'
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
[03/24/2024-10:42:39] [TRT] [I] [MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 43, GPU 480 (MiB)
[03/24/2024-10:42:47] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1958, GPU +346, now: CPU 2106, GPU 826 (MiB)
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 0) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 3) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l0_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 4) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l0_fc_mid_out and (Unnamed Layer* 6) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 11) [ElementWise]_output and (Unnamed Layer* 7) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 13) [ElementWise]_output and (Unnamed Layer* 8) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 15) [Activation]_output and (Unnamed Layer* 9) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 16) [ElementWise]_output and (Unnamed Layer* 10) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l0_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 19) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 4) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 23) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l1_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 24) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l1_fc_mid_out and (Unnamed Layer* 26) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 31) [ElementWise]_output and (Unnamed Layer* 27) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 33) [ElementWise]_output and (Unnamed Layer* 28) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 35) [Activation]_output and (Unnamed Layer* 29) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 36) [ElementWise]_output and (Unnamed Layer* 30) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l1_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 39) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 24) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 43) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l2_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 44) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l2_fc_mid_out and (Unnamed Layer* 46) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 51) [ElementWise]_output and (Unnamed Layer* 47) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 53) [ElementWise]_output and (Unnamed Layer* 48) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 55) [Activation]_output and (Unnamed Layer* 49) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 56) [ElementWise]_output and (Unnamed Layer* 50) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l2_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 59) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 44) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 63) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l3_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 64) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l3_fc_mid_out and (Unnamed Layer* 66) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 71) [ElementWise]_output and (Unnamed Layer* 67) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 73) [ElementWise]_output and (Unnamed Layer* 68) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 75) [Activation]_output and (Unnamed Layer* 69) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 76) [ElementWise]_output and (Unnamed Layer* 70) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l3_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 79) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 64) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 83) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l4_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 84) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l4_fc_mid_out and (Unnamed Layer* 86) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 91) [ElementWise]_output and (Unnamed Layer* 87) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 93) [ElementWise]_output and (Unnamed Layer* 88) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 95) [Activation]_output and (Unnamed Layer* 89) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 96) [ElementWise]_output and (Unnamed Layer* 90) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l4_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 99) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 84) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 103) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l5_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 104) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l5_fc_mid_out and (Unnamed Layer* 106) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 111) [ElementWise]_output and (Unnamed Layer* 107) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 113) [ElementWise]_output and (Unnamed Layer* 108) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 115) [Activation]_output and (Unnamed Layer* 109) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 116) [ElementWise]_output and (Unnamed Layer* 110) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l5_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 119) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 104) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 123) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l6_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 124) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l6_fc_mid_out and (Unnamed Layer* 126) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 131) [ElementWise]_output and (Unnamed Layer* 127) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 133) [ElementWise]_output and (Unnamed Layer* 128) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 135) [Activation]_output and (Unnamed Layer* 129) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 136) [ElementWise]_output and (Unnamed Layer* 130) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l6_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 139) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 124) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 143) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l7_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 144) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l7_fc_mid_out and (Unnamed Layer* 146) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 151) [ElementWise]_output and (Unnamed Layer* 147) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 153) [ElementWise]_output and (Unnamed Layer* 148) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 155) [Activation]_output and (Unnamed Layer* 149) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 156) [ElementWise]_output and (Unnamed Layer* 150) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l7_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 159) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 144) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 163) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l8_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 164) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l8_fc_mid_out and (Unnamed Layer* 166) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 171) [ElementWise]_output and (Unnamed Layer* 167) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 173) [ElementWise]_output and (Unnamed Layer* 168) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 175) [Activation]_output and (Unnamed Layer* 169) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 176) [ElementWise]_output and (Unnamed Layer* 170) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l8_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 179) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 164) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 183) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l9_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 184) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l9_fc_mid_out and (Unnamed Layer* 186) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 191) [ElementWise]_output and (Unnamed Layer* 187) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 193) [ElementWise]_output and (Unnamed Layer* 188) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 195) [Activation]_output and (Unnamed Layer* 189) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 196) [ElementWise]_output and (Unnamed Layer* 190) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l9_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 199) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 184) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 203) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l10_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 204) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l10_fc_mid_out and (Unnamed Layer* 206) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 211) [ElementWise]_output and (Unnamed Layer* 207) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 213) [ElementWise]_output and (Unnamed Layer* 208) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 215) [Activation]_output and (Unnamed Layer* 209) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 216) [ElementWise]_output and (Unnamed Layer* 210) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l10_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 219) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 204) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 223) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l11_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 224) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l11_fc_mid_out and (Unnamed Layer* 226) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 231) [ElementWise]_output and (Unnamed Layer* 227) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 233) [ElementWise]_output and (Unnamed Layer* 228) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 235) [Activation]_output and (Unnamed Layer* 229) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 236) [ElementWise]_output and (Unnamed Layer* 230) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l11_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 239) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 224) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 243) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l12_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 244) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l12_fc_mid_out and (Unnamed Layer* 246) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 251) [ElementWise]_output and (Unnamed Layer* 247) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 253) [ElementWise]_output and (Unnamed Layer* 248) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 255) [Activation]_output and (Unnamed Layer* 249) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 256) [ElementWise]_output and (Unnamed Layer* 250) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l12_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 259) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 244) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 263) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l13_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 264) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l13_fc_mid_out and (Unnamed Layer* 266) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 271) [ElementWise]_output and (Unnamed Layer* 267) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 273) [ElementWise]_output and (Unnamed Layer* 268) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 275) [Activation]_output and (Unnamed Layer* 269) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 276) [ElementWise]_output and (Unnamed Layer* 270) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l13_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 279) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 264) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 283) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l14_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 284) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l14_fc_mid_out and (Unnamed Layer* 286) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 291) [ElementWise]_output and (Unnamed Layer* 287) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 293) [ElementWise]_output and (Unnamed Layer* 288) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 295) [Activation]_output and (Unnamed Layer* 289) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 296) [ElementWise]_output and (Unnamed Layer* 290) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l14_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 299) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 284) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 303) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l15_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 304) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l15_fc_mid_out and (Unnamed Layer* 306) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 311) [ElementWise]_output and (Unnamed Layer* 307) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 313) [ElementWise]_output and (Unnamed Layer* 308) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 315) [Activation]_output and (Unnamed Layer* 309) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 316) [ElementWise]_output and (Unnamed Layer* 310) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l15_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 319) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 304) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 323) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l16_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 324) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l16_fc_mid_out and (Unnamed Layer* 326) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 331) [ElementWise]_output and (Unnamed Layer* 327) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 333) [ElementWise]_output and (Unnamed Layer* 328) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 335) [Activation]_output and (Unnamed Layer* 329) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 336) [ElementWise]_output and (Unnamed Layer* 330) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l16_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 339) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 324) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 343) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l17_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 344) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l17_fc_mid_out and (Unnamed Layer* 346) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 351) [ElementWise]_output and (Unnamed Layer* 347) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 353) [ElementWise]_output and (Unnamed Layer* 348) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 355) [Activation]_output and (Unnamed Layer* 349) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 356) [ElementWise]_output and (Unnamed Layer* 350) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l17_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 359) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 344) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 363) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l18_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 364) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l18_fc_mid_out and (Unnamed Layer* 366) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 371) [ElementWise]_output and (Unnamed Layer* 367) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 373) [ElementWise]_output and (Unnamed Layer* 368) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 375) [Activation]_output and (Unnamed Layer* 369) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 376) [ElementWise]_output and (Unnamed Layer* 370) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l18_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 379) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 364) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 383) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l19_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 384) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l19_fc_mid_out and (Unnamed Layer* 386) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 391) [ElementWise]_output and (Unnamed Layer* 387) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 393) [ElementWise]_output and (Unnamed Layer* 388) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 395) [Activation]_output and (Unnamed Layer* 389) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 396) [ElementWise]_output and (Unnamed Layer* 390) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l19_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 399) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 384) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 403) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l20_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 404) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l20_fc_mid_out and (Unnamed Layer* 406) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 411) [ElementWise]_output and (Unnamed Layer* 407) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 413) [ElementWise]_output and (Unnamed Layer* 408) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 415) [Activation]_output and (Unnamed Layer* 409) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 416) [ElementWise]_output and (Unnamed Layer* 410) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l20_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 419) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 404) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 423) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l21_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 424) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l21_fc_mid_out and (Unnamed Layer* 426) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 431) [ElementWise]_output and (Unnamed Layer* 427) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 433) [ElementWise]_output and (Unnamed Layer* 428) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 435) [Activation]_output and (Unnamed Layer* 429) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 436) [ElementWise]_output and (Unnamed Layer* 430) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l21_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 439) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 424) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 443) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l22_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 444) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l22_fc_mid_out and (Unnamed Layer* 446) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 451) [ElementWise]_output and (Unnamed Layer* 447) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 453) [ElementWise]_output and (Unnamed Layer* 448) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 455) [Activation]_output and (Unnamed Layer* 449) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 456) [ElementWise]_output and (Unnamed Layer* 450) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l22_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 459) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 444) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 463) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l23_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 464) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs l23_fc_mid_out and (Unnamed Layer* 466) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 471) [ElementWise]_output and (Unnamed Layer* 467) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 473) [ElementWise]_output and (Unnamed Layer* 468) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 475) [Activation]_output and (Unnamed Layer* 469) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 476) [ElementWise]_output and (Unnamed Layer* 470) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l23_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 479) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 464) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-10:42:48] [TRT] [W] Calibrator is not being used. Users must provide dynamic range for all tensors that are not Int32 or Bool.
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor input_ids, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor segment_ids, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor cu_seqlens, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor max_seqlen, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l0_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 6) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 7) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 8) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 9) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 10) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 11) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 12) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 13) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 14) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 15) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 16) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 17) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l1_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 26) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 27) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 28) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 29) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 30) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 31) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 32) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 33) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 34) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 35) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 36) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 37) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l2_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 46) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 47) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 48) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 49) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 50) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 51) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 52) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 53) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 54) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 55) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 56) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 57) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l3_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 66) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 67) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 68) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 69) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 70) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 71) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 72) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 73) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 74) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 75) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 76) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 77) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l4_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 86) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 87) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 88) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 89) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 90) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 91) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 92) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 93) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 94) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 95) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 96) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 97) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l5_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 106) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 107) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 108) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 109) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 110) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 111) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 112) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 113) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 114) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 115) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 116) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 117) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l6_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 126) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 127) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 128) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 129) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 130) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 131) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 132) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 133) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 134) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 135) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 136) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 137) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l7_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 146) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 147) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 148) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 149) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 150) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 151) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 152) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 153) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 154) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 155) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 156) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 157) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l8_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 166) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 167) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 168) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 169) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 170) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 171) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 172) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 173) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 174) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 175) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 176) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 177) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l9_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 186) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 187) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 188) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 189) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 190) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 191) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 192) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 193) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 194) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 195) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 196) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 197) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l10_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 206) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 207) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 208) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 209) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 210) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 211) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 212) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 213) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 214) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 215) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 216) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 217) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l11_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 226) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 227) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 228) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 229) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 230) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 231) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 232) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 233) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 234) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 235) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 236) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 237) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l12_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 246) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 247) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 248) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 249) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 250) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 251) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 252) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 253) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 254) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 255) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 256) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 257) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l13_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 266) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 267) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 268) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 269) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 270) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 271) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 272) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 273) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 274) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 275) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 276) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 277) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l14_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 286) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 287) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 288) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 289) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 290) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 291) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 292) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 293) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 294) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 295) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 296) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 297) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l15_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 306) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 307) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 308) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 309) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 310) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 311) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 312) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 313) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 314) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 315) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 316) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 317) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l16_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 326) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 327) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 328) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 329) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 330) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 331) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 332) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 333) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 334) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 335) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 336) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 337) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l17_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 346) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 347) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 348) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 349) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 350) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 351) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 352) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 353) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 354) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 355) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 356) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 357) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l18_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 366) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 367) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 368) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 369) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 370) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 371) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 372) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 373) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 374) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 375) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 376) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 377) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l19_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 386) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 387) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 388) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 389) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 390) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 391) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 392) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 393) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 394) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 395) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 396) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 397) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l20_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 406) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 407) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 408) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 409) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 410) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 411) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 412) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 413) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 414) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 415) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 416) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 417) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l21_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 426) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 427) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 428) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 429) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 430) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 431) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 432) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 433) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 434) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 435) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 436) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 437) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l22_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 446) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 447) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 448) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 449) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 450) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 451) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 452) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 453) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 454) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 455) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 456) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 457) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor l23_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 466) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 467) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 468) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 469) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 470) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 471) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 472) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 473) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 474) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 475) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 476) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:48] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 477) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-10:42:50] [TRT] [I] Graph optimization time: 1.58543 seconds.
[03/24/2024-10:42:50] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +8, now: CPU 3814, GPU 958 (MiB)
[03/24/2024-10:42:50] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 3815, GPU 968 (MiB)
[03/24/2024-10:42:50] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[03/24/2024-10:44:42] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000006080777 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000006080419 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000000060805f3 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000000608076f due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000006080729 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000006080453 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000006080592 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000006080442 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000006080774 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000006080490 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000000608076c due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] [MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 43, GPU 13288 (MiB)
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000000060800b3 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000006080732 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000000608076b due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000000060800e8 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000000060803f3 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000000608038b due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000000060803cc due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060775 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000020606020e due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060777 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060419 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060453 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060729 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000020606076f due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000002060605f3 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060490 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060774 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060592 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060442 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000020606076c due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000002060600b3 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000020606076b due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000206060732 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000020606038b due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000002060603cc due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000002060600e8 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000002060603f3 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000002040623 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000002040771 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000000204054f due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000002040615 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080777 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080419 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000020808020e due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080775 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080729 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000002080805f3 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000020808076f due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080453 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080442 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080592 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080774 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080490 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000020808076c due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000002080800b3 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x0000000208080732 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x000000020808076b due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000002080800e8 due to exception unspecified launch failure
[03/24/2024-12:42:51] [TRT] [I] Skipping tactic 0x00000002080803f3 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000002080803cc due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020808038b due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000000204e4 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000002054a due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x0000000204040771 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x0000000204040623 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x0000000204040615 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020404054f due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a020e due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0775 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0777 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0419 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0729 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0453 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a076f due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a05f3 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0442 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0592 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0732 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a076b due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0490 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a0774 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a076c due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a00b3 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a03cc due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a03f3 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a038b due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x00000000080a00e8 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0777 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0419 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0775 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a020e due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a05f3 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0453 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0729 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a076f due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0442 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0592 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a076b due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0732 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0774 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a0490 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a076c due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a00b3 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a00e8 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a03f3 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a03cc due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000020a0a038b due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x0000000004060771 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x0000000004060623 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000406054f due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x0000000004060615 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c0777 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c0775 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c0419 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c020e due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c0453 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c076f due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c05f3 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c0729 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c0442 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c0592 due to exception unspecified launch failure
[03/24/2024-12:42:52] [TRT] [I] Skipping tactic 0x000000000a0c0774 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000a0c0490 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000a0c076c due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000a0c00b3 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000a0c0732 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000a0c076b due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000a0c00e8 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000a0c03cc due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000a0c03f3 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000a0c038b due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e10020e due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100777 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100775 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100419 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100729 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e1005f3 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100453 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e10076f due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100592 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100442 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000204054a due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x00000000020404e4 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e10076b due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100732 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100490 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e100774 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e10076c due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e1000b3 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e10038b due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e1003f3 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e1000e8 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000e1003cc due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x0000000206060771 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x0000000206060623 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x0000000206060615 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020606054f due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0775 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c020e due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0419 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0777 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c076f due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c05f3 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0729 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0453 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0442 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0592 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0490 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0774 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c076c due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c00b3 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c0732 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c076b due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c038b due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c03f3 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c00e8 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000020c0c03cc due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x0000000006080771 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x0000000006080623 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000000608054f due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x0000000006080615 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x0000000210100775 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x000000021010020e due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x0000000210100419 due to exception unspecified launch failure
[03/24/2024-12:42:53] [TRT] [I] Skipping tactic 0x0000000210100777 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000210100729 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000210100453 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000021010076f due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000002101005f3 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000210100442 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000210100592 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000002040404e4 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000020404054a due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000210100732 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000021010076b due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000210100774 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000210100490 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000021010076c due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000002101000b3 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000021010038b due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000002101003cc due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000002101003f3 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000002101000e8 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0419 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0775 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0777 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e020e due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e076f due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e05f3 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0453 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0729 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0442 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0592 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0490 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0774 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e076c due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e00b3 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e076b due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e0732 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e03cc due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e038b due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e00e8 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000c0e03f3 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120419 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120777 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120775 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000001012020e due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120453 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000000101205f3 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000001012076f due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120729 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120592 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120442 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120490 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120774 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000001012076c due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000000101200b3 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000010120732 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000001012076b due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000000101203cc due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000000101200e8 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000001012038b due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000000101203f3 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x000000000406054a due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x00000000040604e4 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000208080771 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000208080623 due to exception unspecified launch failure
[03/24/2024-12:42:54] [TRT] [I] Skipping tactic 0x0000000208080615 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020808054f due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0419 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0775 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e020e due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0777 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e076f due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0729 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0453 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e05f3 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0592 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0442 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0774 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0490 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e076c due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e00b3 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e0732 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e076b due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e03f3 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e03cc due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e00e8 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020e0e038b due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120777 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000021212020e due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120775 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120419 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000021212076f due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120729 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000002121205f3 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120453 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120592 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120442 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120490 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120774 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000021212076c due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000002121200b3 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000212120732 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000021212076b due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000021212038b due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000002121200e8 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000002121203f3 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000002121203cc due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020606054a due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000002060604e4 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000000608054a due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000000060804e4 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000002080804e4 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000020808054a due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000000080a0623 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000000080a0771 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000000080a054f due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000000080a0615 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000012140777 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000012140775 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000001214020e due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000012140419 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000001214076f due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000012140729 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x00000000121405f3 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000012140453 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000012140442 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000012140592 due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x000000001214076b due to exception unspecified launch failure
[03/24/2024-12:42:55] [TRT] [I] Skipping tactic 0x0000000012140732 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000012140774 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000012140490 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000001214076c due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000121400b3 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000121403f3 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000001214038b due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000121400e8 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000121403cc due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000020a0a0771 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000020a0a0623 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000020a0a0615 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000020a0a054f due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000080a04e4 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000080a054a due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180419 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000001618020e due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180775 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180777 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180453 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000161805f3 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180729 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000001618076f due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180592 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180442 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180732 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000001618076b due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180490 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000016180774 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000001618076c due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000161800b3 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000001618038b due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000161803cc due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000161803f3 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000000161800e8 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000021414020e due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140419 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140777 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140775 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000002141405f3 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140729 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140453 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000021414076f due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140442 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140592 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140732 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000021414076b due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140490 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000214140774 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000021414076c due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000002141400b3 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000002141403cc due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000002141403f3 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000002141400e8 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000021414038b due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000020a0a054a due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000020a0a04e4 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000218180777 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000021818020e due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000218180775 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000218180419 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x00000002181805f3 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x0000000218180453 due to exception unspecified launch failure
[03/24/2024-12:42:56] [TRT] [I] Skipping tactic 0x000000021818076f due to exception unspecified launch failure
[03/24/2024-12:42:57] [TRT] [I] Skipping tactic 0x0000000218180729 due to exception unspecified launch failure
[03/24/2024-12:42:57] [TRT] [I] Skipping tactic 0x0000000218180442 due to exception unspecified launch failure
[03/24/2024-12:42:57] [TRT] [I] Skipping tactic 0x0000000218180592 due to exception unspecified launch failure
[03/24/2024-12:42:57] [TRT] [I] Skipping tactic 0x000000021818076b due to exception unspecified launch failure
[03/24/2024-12:42:57] [TRT] [I] Skipping tactic 0x0000000218180732 due to exception unspecified launch failure
[03/24/2024-12:42:57] [TRT] [I] Skipping tactic 0x0000000218180774 due to exception unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l0_fc_out : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [W] GPU error during getBestTactic: l1_fc_qkv : unspecified launch failure
[03/24/2024-12:42:57] [TRT] [E] /_src/plugin/common/bertCommon.h (300) - Cuda Error in operator(): 719 (unspecified launch failure)
[03/24/2024-12:42:58] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1958, GPU +346, now: CPU 2106, GPU 13634 (MiB)
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 0) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 3) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l0_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 4) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l0_fc_mid_out and (Unnamed Layer* 6) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 11) [ElementWise]_output and (Unnamed Layer* 7) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 13) [ElementWise]_output and (Unnamed Layer* 8) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 15) [Activation]_output and (Unnamed Layer* 9) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 16) [ElementWise]_output and (Unnamed Layer* 10) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l0_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 19) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 4) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 23) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l1_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 24) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l1_fc_mid_out and (Unnamed Layer* 26) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 31) [ElementWise]_output and (Unnamed Layer* 27) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 33) [ElementWise]_output and (Unnamed Layer* 28) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 35) [Activation]_output and (Unnamed Layer* 29) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 36) [ElementWise]_output and (Unnamed Layer* 30) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l1_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 39) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 24) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 43) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l2_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 44) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l2_fc_mid_out and (Unnamed Layer* 46) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 51) [ElementWise]_output and (Unnamed Layer* 47) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 53) [ElementWise]_output and (Unnamed Layer* 48) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 55) [Activation]_output and (Unnamed Layer* 49) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 56) [ElementWise]_output and (Unnamed Layer* 50) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l2_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 59) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 44) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 63) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l3_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 64) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l3_fc_mid_out and (Unnamed Layer* 66) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 71) [ElementWise]_output and (Unnamed Layer* 67) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 73) [ElementWise]_output and (Unnamed Layer* 68) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 75) [Activation]_output and (Unnamed Layer* 69) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 76) [ElementWise]_output and (Unnamed Layer* 70) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l3_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 79) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 64) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 83) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l4_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 84) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l4_fc_mid_out and (Unnamed Layer* 86) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 91) [ElementWise]_output and (Unnamed Layer* 87) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 93) [ElementWise]_output and (Unnamed Layer* 88) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 95) [Activation]_output and (Unnamed Layer* 89) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 96) [ElementWise]_output and (Unnamed Layer* 90) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l4_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 99) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 84) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 103) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l5_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 104) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l5_fc_mid_out and (Unnamed Layer* 106) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 111) [ElementWise]_output and (Unnamed Layer* 107) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 113) [ElementWise]_output and (Unnamed Layer* 108) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 115) [Activation]_output and (Unnamed Layer* 109) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 116) [ElementWise]_output and (Unnamed Layer* 110) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l5_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 119) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 104) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 123) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l6_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 124) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l6_fc_mid_out and (Unnamed Layer* 126) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 131) [ElementWise]_output and (Unnamed Layer* 127) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 133) [ElementWise]_output and (Unnamed Layer* 128) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 135) [Activation]_output and (Unnamed Layer* 129) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 136) [ElementWise]_output and (Unnamed Layer* 130) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l6_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 139) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 124) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 143) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l7_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 144) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l7_fc_mid_out and (Unnamed Layer* 146) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 151) [ElementWise]_output and (Unnamed Layer* 147) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 153) [ElementWise]_output and (Unnamed Layer* 148) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 155) [Activation]_output and (Unnamed Layer* 149) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 156) [ElementWise]_output and (Unnamed Layer* 150) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l7_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 159) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 144) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 163) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l8_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 164) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l8_fc_mid_out and (Unnamed Layer* 166) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 171) [ElementWise]_output and (Unnamed Layer* 167) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 173) [ElementWise]_output and (Unnamed Layer* 168) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 175) [Activation]_output and (Unnamed Layer* 169) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 176) [ElementWise]_output and (Unnamed Layer* 170) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l8_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 179) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 164) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 183) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l9_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 184) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l9_fc_mid_out and (Unnamed Layer* 186) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 191) [ElementWise]_output and (Unnamed Layer* 187) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 193) [ElementWise]_output and (Unnamed Layer* 188) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 195) [Activation]_output and (Unnamed Layer* 189) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 196) [ElementWise]_output and (Unnamed Layer* 190) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l9_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 199) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 184) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 203) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l10_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 204) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l10_fc_mid_out and (Unnamed Layer* 206) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 211) [ElementWise]_output and (Unnamed Layer* 207) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 213) [ElementWise]_output and (Unnamed Layer* 208) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 215) [Activation]_output and (Unnamed Layer* 209) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 216) [ElementWise]_output and (Unnamed Layer* 210) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l10_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 219) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 204) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 223) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l11_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 224) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l11_fc_mid_out and (Unnamed Layer* 226) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 231) [ElementWise]_output and (Unnamed Layer* 227) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 233) [ElementWise]_output and (Unnamed Layer* 228) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 235) [Activation]_output and (Unnamed Layer* 229) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 236) [ElementWise]_output and (Unnamed Layer* 230) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l11_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 239) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 224) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 243) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l12_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 244) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l12_fc_mid_out and (Unnamed Layer* 246) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 251) [ElementWise]_output and (Unnamed Layer* 247) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 253) [ElementWise]_output and (Unnamed Layer* 248) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 255) [Activation]_output and (Unnamed Layer* 249) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 256) [ElementWise]_output and (Unnamed Layer* 250) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l12_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 259) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 244) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 263) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l13_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 264) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l13_fc_mid_out and (Unnamed Layer* 266) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 271) [ElementWise]_output and (Unnamed Layer* 267) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 273) [ElementWise]_output and (Unnamed Layer* 268) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 275) [Activation]_output and (Unnamed Layer* 269) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 276) [ElementWise]_output and (Unnamed Layer* 270) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l13_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 279) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 264) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 283) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l14_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 284) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l14_fc_mid_out and (Unnamed Layer* 286) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 291) [ElementWise]_output and (Unnamed Layer* 287) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 293) [ElementWise]_output and (Unnamed Layer* 288) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 295) [Activation]_output and (Unnamed Layer* 289) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 296) [ElementWise]_output and (Unnamed Layer* 290) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l14_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 299) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 284) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 303) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l15_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 304) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l15_fc_mid_out and (Unnamed Layer* 306) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 311) [ElementWise]_output and (Unnamed Layer* 307) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 313) [ElementWise]_output and (Unnamed Layer* 308) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 315) [Activation]_output and (Unnamed Layer* 309) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 316) [ElementWise]_output and (Unnamed Layer* 310) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l15_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 319) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 304) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 323) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l16_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 324) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l16_fc_mid_out and (Unnamed Layer* 326) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 331) [ElementWise]_output and (Unnamed Layer* 327) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 333) [ElementWise]_output and (Unnamed Layer* 328) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 335) [Activation]_output and (Unnamed Layer* 329) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 336) [ElementWise]_output and (Unnamed Layer* 330) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l16_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 339) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 324) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 343) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l17_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 344) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l17_fc_mid_out and (Unnamed Layer* 346) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 351) [ElementWise]_output and (Unnamed Layer* 347) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 353) [ElementWise]_output and (Unnamed Layer* 348) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 355) [Activation]_output and (Unnamed Layer* 349) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 356) [ElementWise]_output and (Unnamed Layer* 350) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l17_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 359) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 344) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 363) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l18_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 364) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l18_fc_mid_out and (Unnamed Layer* 366) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 371) [ElementWise]_output and (Unnamed Layer* 367) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 373) [ElementWise]_output and (Unnamed Layer* 368) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 375) [Activation]_output and (Unnamed Layer* 369) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 376) [ElementWise]_output and (Unnamed Layer* 370) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l18_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 379) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 364) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 383) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l19_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 384) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l19_fc_mid_out and (Unnamed Layer* 386) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 391) [ElementWise]_output and (Unnamed Layer* 387) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 393) [ElementWise]_output and (Unnamed Layer* 388) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 395) [Activation]_output and (Unnamed Layer* 389) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 396) [ElementWise]_output and (Unnamed Layer* 390) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l19_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 399) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 384) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 403) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l20_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 404) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l20_fc_mid_out and (Unnamed Layer* 406) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 411) [ElementWise]_output and (Unnamed Layer* 407) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 413) [ElementWise]_output and (Unnamed Layer* 408) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 415) [Activation]_output and (Unnamed Layer* 409) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 416) [ElementWise]_output and (Unnamed Layer* 410) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l20_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 419) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 404) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 423) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l21_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 424) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l21_fc_mid_out and (Unnamed Layer* 426) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 431) [ElementWise]_output and (Unnamed Layer* 427) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 433) [ElementWise]_output and (Unnamed Layer* 428) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 435) [Activation]_output and (Unnamed Layer* 429) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 436) [ElementWise]_output and (Unnamed Layer* 430) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l21_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 439) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 424) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 443) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l22_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 444) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l22_fc_mid_out and (Unnamed Layer* 446) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 451) [ElementWise]_output and (Unnamed Layer* 447) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 453) [ElementWise]_output and (Unnamed Layer* 448) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 455) [Activation]_output and (Unnamed Layer* 449) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 456) [ElementWise]_output and (Unnamed Layer* 450) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l22_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 459) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 444) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [I] Using default for use_int8_scale_max: true
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 463) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l23_attention_fc_aout. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 464) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs l23_fc_mid_out and (Unnamed Layer* 466) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 471) [ElementWise]_output and (Unnamed Layer* 467) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 473) [ElementWise]_output and (Unnamed Layer* 468) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 475) [Activation]_output and (Unnamed Layer* 469) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] IElementWiseLayer with inputs (Unnamed Layer* 476) [ElementWise]_output and (Unnamed Layer* 470) [Constant]_output: first input has type Half but second input has type Float.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: l23_gelu_out. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 479) [Convolution]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] ITensor::setType(Int8) was called on non I/O tensor: (Unnamed Layer* 464) [PluginV2DynamicExt]_output. This will have no effect unless this tensor is marked as an output.
[03/24/2024-12:43:00] [TRT] [W] Calibrator is not being used. Users must provide dynamic range for all tensors that are not Int32 or Bool.
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor input_ids, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor segment_ids, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor cu_seqlens, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor max_seqlen, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l0_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 6) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 7) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 8) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 9) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 10) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 11) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 12) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 13) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 14) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 15) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 16) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 17) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l1_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 26) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 27) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 28) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 29) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 30) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 31) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 32) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 33) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 34) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 35) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 36) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 37) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l2_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 46) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 47) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 48) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 49) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 50) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 51) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 52) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 53) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 54) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 55) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 56) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 57) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l3_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 66) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 67) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 68) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 69) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 70) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 71) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 72) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 73) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 74) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 75) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 76) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 77) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l4_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 86) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 87) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 88) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 89) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 90) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 91) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 92) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 93) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 94) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 95) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 96) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 97) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l5_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 106) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 107) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 108) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 109) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 110) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 111) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 112) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 113) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 114) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 115) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 116) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 117) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l6_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 126) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 127) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 128) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 129) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 130) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 131) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 132) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 133) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 134) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 135) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 136) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 137) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l7_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 146) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 147) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 148) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 149) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 150) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 151) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 152) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 153) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 154) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 155) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 156) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 157) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l8_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 166) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 167) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 168) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 169) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 170) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 171) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 172) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 173) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 174) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 175) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 176) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 177) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l9_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 186) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 187) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 188) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 189) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 190) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 191) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 192) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 193) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 194) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 195) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 196) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 197) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l10_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 206) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 207) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 208) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 209) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 210) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 211) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 212) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 213) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 214) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 215) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 216) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 217) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l11_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 226) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 227) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 228) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 229) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 230) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 231) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 232) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 233) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 234) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 235) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 236) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 237) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l12_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 246) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 247) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 248) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 249) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 250) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 251) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 252) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 253) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 254) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 255) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 256) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 257) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l13_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 266) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 267) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 268) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 269) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 270) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 271) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 272) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 273) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 274) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 275) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 276) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 277) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l14_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 286) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 287) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 288) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 289) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 290) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 291) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 292) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 293) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 294) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 295) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 296) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 297) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l15_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 306) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 307) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 308) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 309) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 310) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 311) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 312) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 313) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 314) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 315) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 316) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 317) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l16_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 326) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 327) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 328) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 329) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 330) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 331) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 332) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 333) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 334) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 335) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 336) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 337) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l17_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 346) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 347) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 348) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 349) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 350) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 351) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 352) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 353) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 354) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 355) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 356) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 357) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l18_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 366) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 367) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 368) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 369) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 370) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 371) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 372) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 373) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 374) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 375) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 376) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 377) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l19_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 386) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 387) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 388) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 389) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 390) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 391) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 392) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 393) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 394) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 395) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 396) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 397) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l20_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 406) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 407) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 408) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 409) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 410) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 411) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 412) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 413) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 414) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 415) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 416) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 417) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l21_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 426) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 427) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 428) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 429) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 430) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 431) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 432) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 433) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 434) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 435) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 436) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 437) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l22_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 446) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 447) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 448) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 449) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 450) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 451) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 452) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 453) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 454) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 455) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 456) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 457) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor l23_fc_mid_out, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 466) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 467) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 468) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 469) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 470) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 471) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 472) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 473) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 474) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 475) [Activation]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 476) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:00] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 477) [ElementWise]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor
[03/24/2024-12:43:02] [TRT] [I] Graph optimization time: 2.15803 seconds.
[03/24/2024-12:43:02] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +8, now: CPU 3814, GPU 13766 (MiB)
[03/24/2024-12:43:02] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 3815, GPU 13776 (MiB)
[03/24/2024-12:43:02] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[03/24/2024-12:44:20] [TRT] [E] 2: [virtualMemoryBuffer.cpp::resizePhysical::140] Error Code 2: OutOfMemory (no further information)
[03/24/2024-12:44:49] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.
