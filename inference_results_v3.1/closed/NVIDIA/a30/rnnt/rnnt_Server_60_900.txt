$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
make[1]: Entering directory '/work'
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
[04/08/2024-03:22:27] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 126, GPU 480 (MiB)
[04/08/2024-03:22:35] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1957, GPU +346, now: CPU 2188, GPU 826 (MiB)
[04/08/2024-03:22:35] [TRT] [I] Graph optimization time: 0.000351611 seconds.
[04/08/2024-03:22:35] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +10, now: CPU 2532, GPU 836 (MiB)
[04/08/2024-03:22:35] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2533, GPU 846 (MiB)
[04/08/2024-03:22:35] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/08/2024-03:22:36] [TRT] [I] Detected 7 inputs and 5 output network tensors.
[04/08/2024-03:22:36] [TRT] [I] Total Host Persistent Memory: 896
[04/08/2024-03:22:36] [TRT] [I] Total Device Persistent Memory: 0
[04/08/2024-03:22:36] [TRT] [I] Total Scratch Memory: 112497120
[04/08/2024-03:22:36] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 8 steps to complete.
[04/08/2024-03:22:36] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.033844ms to assign 5 blocks to 8 nodes requiring 128227328 bytes.
[04/08/2024-03:22:36] [TRT] [I] Total Activation Memory: 128226304
[04/08/2024-03:22:36] [TRT] [I] Total Weights Memory: 516
[04/08/2024-03:22:36] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2674, GPU 856 (MiB)
[04/08/2024-03:22:36] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2674, GPU 866 (MiB)
[04/08/2024-03:22:37] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 94 MiB
[04/08/2024-03:22:37] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[04/08/2024-03:22:37] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/08/2024-03:22:38] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 472, GPU 490 (MiB)
[04/08/2024-03:22:45] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1956, GPU +342, now: CPU 2428, GPU 832 (MiB)
[04/08/2024-03:22:45] [TRT] [I] Graph optimization time: 0.000255499 seconds.
[04/08/2024-03:22:45] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2435, GPU 842 (MiB)
[04/08/2024-03:22:45] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2435, GPU 850 (MiB)
[04/08/2024-03:22:45] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/08/2024-03:22:46] [TRT] [I] Detected 3 inputs and 3 output network tensors.
[04/08/2024-03:22:46] [TRT] [I] Total Host Persistent Memory: 368
[04/08/2024-03:22:46] [TRT] [I] Total Device Persistent Memory: 0
[04/08/2024-03:22:46] [TRT] [I] Total Scratch Memory: 537600
[04/08/2024-03:22:46] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 2 steps to complete.
[04/08/2024-03:22:46] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.005259ms to assign 2 blocks to 2 nodes requiring 576000 bytes.
[04/08/2024-03:22:46] [TRT] [I] Total Activation Memory: 576000
[04/08/2024-03:22:46] [TRT] [I] Total Weights Memory: 18584
[04/08/2024-03:22:46] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2443, GPU 862 (MiB)
[04/08/2024-03:22:46] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2443, GPU 870 (MiB)
[04/08/2024-03:22:46] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 94 MiB
[04/08/2024-03:22:46] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[04/08/2024-03:22:46] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/08/2024-03:22:46] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 486, GPU 494 (MiB)
[04/08/2024-03:22:53] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1956, GPU +340, now: CPU 2442, GPU 834 (MiB)
[04/08/2024-03:22:53] [TRT] [I] Graph optimization time: 0.000177569 seconds.
[04/08/2024-03:22:53] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2443, GPU 844 (MiB)
[04/08/2024-03:22:53] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2443, GPU 852 (MiB)
[04/08/2024-03:22:53] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/08/2024-03:22:53] [TRT] [I] Detected 7 inputs and 3 output network tensors.
[04/08/2024-03:22:53] [TRT] [I] Total Host Persistent Memory: 560
[04/08/2024-03:22:53] [TRT] [I] Total Device Persistent Memory: 0
[04/08/2024-03:22:53] [TRT] [I] Total Scratch Memory: 0
[04/08/2024-03:22:53] [TRT] [I] Total Activation Memory: 0
[04/08/2024-03:22:53] [TRT] [I] Total Weights Memory: 0
[04/08/2024-03:22:53] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2443, GPU 860 (MiB)
[04/08/2024-03:22:53] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2443, GPU 868 (MiB)
[04/08/2024-03:22:53] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 94 MiB
[04/08/2024-03:22:53] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[04/08/2024-03:22:53] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/08/2024-03:22:54] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 486, GPU 494 (MiB)
[04/08/2024-03:23:01] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1956, GPU +340, now: CPU 2442, GPU 834 (MiB)
[04/08/2024-03:23:01] [TRT] [I] Graph optimization time: 0.000146863 seconds.
[04/08/2024-03:23:01] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +10, now: CPU 2443, GPU 844 (MiB)
[04/08/2024-03:23:01] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2443, GPU 852 (MiB)
[04/08/2024-03:23:01] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/08/2024-03:23:01] [TRT] [I] Detected 2 inputs and 1 output network tensors.
[04/08/2024-03:23:01] [TRT] [I] Total Host Persistent Memory: 32
[04/08/2024-03:23:01] [TRT] [I] Total Device Persistent Memory: 0
[04/08/2024-03:23:01] [TRT] [I] Total Scratch Memory: 0
[04/08/2024-03:23:01] [TRT] [I] Total Activation Memory: 0
[04/08/2024-03:23:01] [TRT] [I] Total Weights Memory: 8
[04/08/2024-03:23:01] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 94 MiB
[04/08/2024-03:23:01] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[04/08/2024-03:23:01] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/08/2024-03:23:01] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 486, GPU 494 (MiB)
[04/08/2024-03:23:09] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1957, GPU +340, now: CPU 2443, GPU 834 (MiB)
[04/08/2024-03:23:10] [TRT] [I] Graph optimization time: 0.000103012 seconds.
[04/08/2024-03:23:10] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2445, GPU 844 (MiB)
[04/08/2024-03:23:10] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2445, GPU 852 (MiB)
[04/08/2024-03:23:10] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/08/2024-03:23:12] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[04/08/2024-03:23:12] [TRT] [I] Total Host Persistent Memory: 7648
[04/08/2024-03:23:12] [TRT] [I] Total Device Persistent Memory: 0
[04/08/2024-03:23:12] [TRT] [I] Total Scratch Memory: 0
[04/08/2024-03:23:12] [TRT] [I] Total Activation Memory: 0
[04/08/2024-03:23:12] [TRT] [I] Total Weights Memory: 1049600
[04/08/2024-03:23:12] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 94 MiB
[04/08/2024-03:23:12] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +2, now: CPU 0, GPU 2 (MiB)
[04/08/2024-03:23:12] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/08/2024-03:23:12] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 604, GPU 498 (MiB)
[04/08/2024-03:23:19] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1956, GPU +338, now: CPU 2560, GPU 836 (MiB)
[04/08/2024-03:23:19] [TRT] [I] Graph optimization time: 0.000100612 seconds.
[04/08/2024-03:23:19] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2561, GPU 846 (MiB)
[04/08/2024-03:23:19] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2561, GPU 854 (MiB)
[04/08/2024-03:23:19] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/08/2024-03:23:20] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[04/08/2024-03:23:20] [TRT] [I] Total Host Persistent Memory: 7648
[04/08/2024-03:23:20] [TRT] [I] Total Device Persistent Memory: 0
[04/08/2024-03:23:20] [TRT] [I] Total Scratch Memory: 0
[04/08/2024-03:23:20] [TRT] [I] Total Activation Memory: 0
[04/08/2024-03:23:20] [TRT] [I] Total Weights Memory: 327680
[04/08/2024-03:23:20] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 94 MiB
[04/08/2024-03:23:20] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[04/08/2024-03:23:20] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/08/2024-03:23:21] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 604, GPU 500 (MiB)
[04/08/2024-03:23:28] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1956, GPU +336, now: CPU 2560, GPU 836 (MiB)
[04/08/2024-03:23:28] [TRT] [I] Graph optimization time: 0.000263745 seconds.
[04/08/2024-03:23:28] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2560, GPU 846 (MiB)
[04/08/2024-03:23:28] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2560, GPU 854 (MiB)
[04/08/2024-03:23:28] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/08/2024-03:23:54] [TRT] [I] Detected 2 inputs and 1 output network tensors.
[04/08/2024-03:23:54] [TRT] [I] Total Host Persistent Memory: 8000
[04/08/2024-03:23:54] [TRT] [I] Total Device Persistent Memory: 0
[04/08/2024-03:23:54] [TRT] [I] Total Scratch Memory: 1920
[04/08/2024-03:23:54] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 7 steps to complete.
[04/08/2024-03:23:54] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.018447ms to assign 3 blocks to 7 nodes requiring 66048 bytes.
[04/08/2024-03:23:54] [TRT] [I] Total Activation Memory: 66048
[04/08/2024-03:23:54] [TRT] [I] Total Weights Memory: 32832
[04/08/2024-03:23:54] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 94 MiB
[04/08/2024-03:23:54] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[04/08/2024-03:23:54] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
Loading TensorRT plugin from build/plugins/RNNTOptPlugin/librnntoptplugin.so
Initializing DALI with parameters:
	        __class__ : <class 'code.rnnt.dali.pipeline.DALIInferencePipeline'>
	 audio_fp16_input : True
	       batch_size : 16
	           device : gpu
	        device_id : 0
	           dither : 1e-05
	   frame_splicing : 3
	         highfreq : 0
	              log : True
	          lowfreq : 0
	     max_duration : 16.7
	            n_fft : 512
	            nfilt : 80
	        normalize : per_feature
	      num_threads : 2
	           pad_to : 8
	          preemph : 0.97
	processing_layout : tf
	   resample_range : None
	      sample_rate : 16000
	             self : <code.rnnt.dali.pipeline.DALIInferencePipeline object at 0x7fb90dbd6220>
	    total_samples : 16
	           window : hann
	      window_size : 0.02
	    window_stride : 0.01
self.n_fft = 512
self.hop_length = 160
self.win_length = 320
self.window_tensor = tensor([0.0000e+00, 9.6977e-05, 3.8791e-04, 8.7264e-04, 1.5510e-03, 2.4227e-03,
        3.4875e-03, 4.7449e-03, 6.1944e-03, 7.8355e-03, 9.6675e-03, 1.1690e-02,
        1.3901e-02, 1.6302e-02, 1.8890e-02, 2.1664e-02, 2.4624e-02, 2.7769e-02,
        3.1096e-02, 3.4606e-02, 3.8296e-02, 4.2165e-02, 4.6212e-02, 5.0435e-02,
        5.4833e-02, 5.9403e-02, 6.4144e-02, 6.9054e-02, 7.4131e-02, 7.9373e-02,
        8.4779e-02, 9.0346e-02, 9.6071e-02, 1.0195e-01, 1.0799e-01, 1.1418e-01,
        1.2052e-01, 1.2700e-01, 1.3363e-01, 1.4041e-01, 1.4732e-01, 1.5437e-01,
        1.6155e-01, 1.6886e-01, 1.7631e-01, 1.8388e-01, 1.9157e-01, 1.9938e-01,
        2.0730e-01, 2.1534e-01, 2.2350e-01, 2.3175e-01, 2.4012e-01, 2.4858e-01,
        2.5714e-01, 2.6580e-01, 2.7454e-01, 2.8338e-01, 2.9229e-01, 3.0129e-01,
        3.1037e-01, 3.1951e-01, 3.2873e-01, 3.3802e-01, 3.4737e-01, 3.5677e-01,
        3.6624e-01, 3.7575e-01, 3.8531e-01, 3.9492e-01, 4.0457e-01, 4.1425e-01,
        4.2397e-01, 4.3372e-01, 4.4349e-01, 4.5329e-01, 4.6310e-01, 4.7293e-01,
        4.8277e-01, 4.9261e-01, 5.0246e-01, 5.1231e-01, 5.2215e-01, 5.3198e-01,
        5.4181e-01, 5.5161e-01, 5.6140e-01, 5.7116e-01, 5.8089e-01, 5.9059e-01,
        6.0026e-01, 6.0989e-01, 6.1947e-01, 6.2901e-01, 6.3850e-01, 6.4794e-01,
        6.5732e-01, 6.6663e-01, 6.7588e-01, 6.8507e-01, 6.9418e-01, 7.0322e-01,
        7.1218e-01, 7.2105e-01, 7.2984e-01, 7.3854e-01, 7.4715e-01, 7.5566e-01,
        7.6408e-01, 7.7239e-01, 7.8059e-01, 7.8869e-01, 7.9667e-01, 8.0454e-01,
        8.1229e-01, 8.1992e-01, 8.2743e-01, 8.3481e-01, 8.4206e-01, 8.4917e-01,
        8.5616e-01, 8.6300e-01, 8.6970e-01, 8.7626e-01, 8.8267e-01, 8.8893e-01,
        8.9505e-01, 9.0101e-01, 9.0681e-01, 9.1246e-01, 9.1794e-01, 9.2327e-01,
        9.2843e-01, 9.3342e-01, 9.3825e-01, 9.4290e-01, 9.4739e-01, 9.5170e-01,
        9.5583e-01, 9.5979e-01, 9.6357e-01, 9.6717e-01, 9.7059e-01, 9.7383e-01,
        9.7688e-01, 9.7975e-01, 9.8243e-01, 9.8492e-01, 9.8723e-01, 9.8935e-01,
        9.9127e-01, 9.9301e-01, 9.9455e-01, 9.9591e-01, 9.9707e-01, 9.9804e-01,
        9.9881e-01, 9.9939e-01, 9.9978e-01, 9.9998e-01, 9.9998e-01, 9.9978e-01,
        9.9939e-01, 9.9881e-01, 9.9804e-01, 9.9707e-01, 9.9591e-01, 9.9455e-01,
        9.9301e-01, 9.9127e-01, 9.8935e-01, 9.8723e-01, 9.8492e-01, 9.8243e-01,
        9.7975e-01, 9.7688e-01, 9.7383e-01, 9.7059e-01, 9.6717e-01, 9.6357e-01,
        9.5979e-01, 9.5583e-01, 9.5170e-01, 9.4739e-01, 9.4290e-01, 9.3825e-01,
        9.3342e-01, 9.2843e-01, 9.2327e-01, 9.1794e-01, 9.1246e-01, 9.0681e-01,
        9.0101e-01, 8.9505e-01, 8.8893e-01, 8.8267e-01, 8.7626e-01, 8.6970e-01,
        8.6300e-01, 8.5616e-01, 8.4917e-01, 8.4206e-01, 8.3481e-01, 8.2743e-01,
        8.1992e-01, 8.1229e-01, 8.0454e-01, 7.9667e-01, 7.8869e-01, 7.8059e-01,
        7.7239e-01, 7.6408e-01, 7.5566e-01, 7.4715e-01, 7.3854e-01, 7.2984e-01,
        7.2105e-01, 7.1218e-01, 7.0322e-01, 6.9418e-01, 6.8507e-01, 6.7589e-01,
        6.6663e-01, 6.5732e-01, 6.4794e-01, 6.3850e-01, 6.2901e-01, 6.1947e-01,
        6.0989e-01, 6.0026e-01, 5.9059e-01, 5.8089e-01, 5.7116e-01, 5.6140e-01,
        5.5161e-01, 5.4181e-01, 5.3198e-01, 5.2215e-01, 5.1231e-01, 5.0246e-01,
        4.9261e-01, 4.8277e-01, 4.7293e-01, 4.6310e-01, 4.5329e-01, 4.4349e-01,
        4.3372e-01, 4.2397e-01, 4.1425e-01, 4.0457e-01, 3.9492e-01, 3.8531e-01,
        3.7575e-01, 3.6624e-01, 3.5677e-01, 3.4737e-01, 3.3802e-01, 3.2873e-01,
        3.1951e-01, 3.1037e-01, 3.0129e-01, 2.9229e-01, 2.8338e-01, 2.7454e-01,
        2.6580e-01, 2.5714e-01, 2.4858e-01, 2.4012e-01, 2.3175e-01, 2.2350e-01,
        2.1534e-01, 2.0730e-01, 1.9938e-01, 1.9157e-01, 1.8388e-01, 1.7631e-01,
        1.6886e-01, 1.6155e-01, 1.5437e-01, 1.4732e-01, 1.4041e-01, 1.3363e-01,
        1.2700e-01, 1.2052e-01, 1.1418e-01, 1.0799e-01, 1.0195e-01, 9.6071e-02,
        9.0346e-02, 8.4779e-02, 7.9373e-02, 7.4131e-02, 6.9054e-02, 6.4144e-02,
        5.9403e-02, 5.4833e-02, 5.0435e-02, 4.6212e-02, 4.2165e-02, 3.8296e-02,
        3.4606e-02, 3.1096e-02, 2.7769e-02, 2.4624e-02, 2.1664e-02, 1.8889e-02,
        1.6302e-02, 1.3901e-02, 1.1690e-02, 9.6675e-03, 7.8355e-03, 6.1944e-03,
        4.7449e-03, 3.4875e-03, 2.4227e-03, 1.5510e-03, 8.7264e-04, 3.8791e-04,
        9.6977e-05, 2.9802e-08])
self.sample_rate = 16000
self.window_size = 0.02
self.window_stride = 0.01
self.lowfreq = 0
self.device = gpu
Time taken to generate engines: 88.41309428215027 seconds
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
[2024-04-08 03:24:07,681 main.py:230 INFO] Detected system ID: KnownSystem.ocejon
[2024-04-08 03:24:07,844 harness.py:236 INFO] The harness will load 1 plugins: ['build/plugins/RNNTOptPlugin/librnntoptplugin.so']
[2024-04-08 03:24:07,858 generate_conf_files.py:107 INFO] Generated measurements/ entries for ocejon_TRT/rnnt/Server
[2024-04-08 03:24:07,858 __init__.py:46 INFO] Running command: ./build/bin/harness_rnnt --plugins="build/plugins/RNNTOptPlugin/librnntoptplugin.so" --logfile_outdir="/work/build/logs/2024.04.08-03.22.12/ocejon_TRT/rnnt/Server" --logfile_prefix="mlperf_log_" --performance_sample_count=2513 --audio_batch_size=1024 --audio_buffer_num_lines=4096 --audio_fp16_input=true --dali_batches_issue_ahead=0 --dali_pipeline_depth=2 --num_warmups=20480 --mlperf_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/Server/mlperf.conf" --user_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/Server/user.conf" --batch_size=60 --cuda_graph=true --pipelined_execution=true --batch_sorting=false --enable_audio_processing=true --use_copy_kernel=true --streams_per_gpu=1 --start_from_device=false --audio_serialized_pipeline_file="build/bin/dali/dali_pipeline_gpu_fp16.pth" --scenario Server --model rnnt --engine_dir="./build/engines/ocejon/rnnt/Server"
[2024-04-08 03:24:07,858 __init__.py:53 INFO] Overriding Environment
audio_batch_size : 1024
audio_buffer_num_lines : 4096
audio_fp16_input : True
benchmark : Benchmark.RNNT
buffer_manager_thread_count : 0
dali_batches_issue_ahead : 0
dali_pipeline_depth : 2
data_dir : /scratch/gonisla//data
gpu_batch_size : 60
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : fp16
input_format : linear
log_dir : /work/build/logs/2024.04.08-03.22.12
map_path : data_maps/rnnt_dev_clean_512/val_map.txt
nobatch_sorting : True
num_warmups : 20480
precision : fp16
preprocessed_data_dir : /scratch/gonisla//preprocessed_data
scenario : Scenario.Server
server_target_qps : 900
system : SystemConfiguration(host_cpu_conf=CPUConfiguration(layout={CPU(name='Intel(R) Xeon(R) Silver 4314 CPU @ 2.40GHz', architecture=<CPUArchitecture.x86_64: AliasedName(name='x86_64', aliases=(), patterns=())>, core_count=16, threads_per_core=1): 1}), host_mem_conf=MemoryConfiguration(host_memory_capacity=Memory(quantity=65.551536, byte_suffix=<ByteSuffix.GB: (1000, 3)>, _num_bytes=65551536000), comparison_tolerance=0.05), accelerator_conf=AcceleratorConfiguration(layout=defaultdict(<class 'int'>, {GPU(name='NVIDIA A30', accelerator_type=<AcceleratorType.Discrete: AliasedName(name='Discrete', aliases=(), patterns=())>, vram=Memory(quantity=24.0, byte_suffix=<ByteSuffix.GiB: (1024, 3)>, _num_bytes=25769803776), max_power_limit=165.0, pci_id='0x20B710DE', compute_sm=80): 1})), numa_conf=None, system_id='ocejon')
tensor_path : build/preprocessed_data/rnnt_dev_clean_512/fp16
use_graphs : True
system_id : ocejon
config_name : ocejon_rnnt_Server
workload_setting : WorkloadSetting(HarnessType.Custom, AccuracyTarget.k_99, PowerSetting.MaxP)
optimization_level : plugin-enabled
use_cpu : False
use_inferentia : False
num_profiles : 1
config_ver : custom_k_99_MaxP
accuracy_level : 99%
inference_server : custom
skip_file_checks : False
power_limit : None
cpu_freq : None
&&&& RUNNING RNN-T_Harness # ./build/bin/harness_rnnt
I0408 03:24:07.918800 37838 main_rnnt.cc:2903] Found 1 GPUs
[I] Starting creating QSL.
[I] Finished creating QSL.
[I] Starting creating SUT.
[I] Set to device 0
Dali pipeline creating..
Dali pipeline created
[I] Creating stream 0/1
[I] [TRT] Loaded engine size: 81 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +10, now: CPU 215, GPU 3386 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 216, GPU 3396 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 217, GPU 3446 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 217, GPU 3454 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +122, now: CPU 0, GPU 122 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntEncoder runner: encoder
[I] [TRT] Loaded engine size: 3 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 223, GPU 3586 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 224, GPU 3596 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 122 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 224, GPU 3600 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 224, GPU 3608 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 122 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntDecoder runner: decoder
[I] [TRT] Loaded engine size: 1 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +1, now: CPU 0, GPU 123 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 123 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointFc1 runner: fc1_a
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +1, now: CPU 0, GPU 124 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 124 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointFc1 runner: fc1_b
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 124 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 124 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointBackend runner: joint_backend
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 225, GPU 3622 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 226, GPU 3632 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 124 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 225, GPU 3624 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +8, now: CPU 226, GPU 3632 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 124 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntIsel runner: isel
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 124 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 124 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntIgather runner: igather
[I] Instantiated RnntEngineContainer runner
cudaMemcpy blocking 
cudaMemcpy blocking 
[I] Instantiated RnntTensorContainer host memory
Stream::Stream sampleSize: 61440
Stream::Stream singleSampleSize: 480
Stream::Stream fullseqSampleSize: 61440
Stream::Stream mBatchSize: 60
[I] Finished creating SUT.
[I] Starting warming up SUT.
[I] Finished warming up SUT.
[I] Starting running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : RNNT SERVER
Scenario : Server
Mode     : PerformanceOnly
Scheduled samples per second : 898.94
Result is : VALID
  Performance constraints satisfied : Yes
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes
Early Stopping Result:
 * Run successful.

================================================
Additional Stats
================================================
Completed samples per second    : 898.86

Min latency (ns)                : 48631803
Max latency (ns)                : 240777279
Mean latency (ns)               : 104196181
50.00 percentile latency (ns)   : 102248069
90.00 percentile latency (ns)   : 139390786
95.00 percentile latency (ns)   : 150935230
97.00 percentile latency (ns)   : 157951514
99.00 percentile latency (ns)   : 165962786
99.90 percentile latency (ns)   : 174478674

================================================
Test Parameters Used
================================================
samples_per_query : 1
target_qps : 900
target_latency (ns): 1000000000
max_async_queries : 0
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 100
max_query_count : 0
qsl_rng_seed : 148687905518835231
sample_index_rng_seed : 520418551913322573
schedule_rng_seed : 811580660758947900
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
accuracy_log_sampling_target : 0
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 2513

No warnings encountered during test.

No errors encountered during test.
[I] Finished running actual test.
&&&& PASSED RNN-T_Harness # ./build/bin/harness_rnnt
[2024-04-08 03:34:21,855 run_harness.py:167 INFO] Result: result_scheduled_samples_per_sec: 898.945, Result is VALID
 
======================== Result summaries: ========================

 ocejon_TRT-custom_k_99_MaxP-Server:
   rnnt:
     performance: result_scheduled_samples_per_sec: 898.945, Result is VALID
 

======================== Extra Perf Stats: ========================

 ocejon_TRT-custom_k_99_MaxP-Server:
    FileNotFoundError: Cannot find perf logs for ocejon_TRT/rnnt/Server at build/artifacts/closed/NVIDIA/results/ocejon_TRT/rnnt/Server/performance/run_1. Non-NVIDIA users ignore this. NVIDIA users run `make pull_artifacts_repo`.
    Server 99-percentile latency 165962786 ns is 0.17 of the target_latency 1000000000 ns
make[1]: Leaving directory '/work'
