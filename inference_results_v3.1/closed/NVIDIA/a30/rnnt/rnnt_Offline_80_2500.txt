$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
make[1]: Entering directory '/work'
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
[05/22/2024-17:57:09] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 126, GPU 480 (MiB)
[05/22/2024-17:57:17] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1957, GPU +346, now: CPU 2188, GPU 826 (MiB)
[05/22/2024-17:57:17] [TRT] [I] Graph optimization time: 0.000345685 seconds.
[05/22/2024-17:57:17] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +10, now: CPU 2532, GPU 836 (MiB)
[05/22/2024-17:57:17] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2533, GPU 846 (MiB)
[05/22/2024-17:57:17] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/22/2024-17:57:18] [TRT] [I] Detected 6 inputs and 5 output network tensors.
[05/22/2024-17:57:18] [TRT] [I] Total Host Persistent Memory: 4896
[05/22/2024-17:57:18] [TRT] [I] Total Device Persistent Memory: 5120
[05/22/2024-17:57:18] [TRT] [I] Total Scratch Memory: 140184464
[05/22/2024-17:57:18] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 7 steps to complete.
[05/22/2024-17:57:18] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.026623ms to assign 4 blocks to 7 nodes requiring 161157120 bytes.
[05/22/2024-17:57:18] [TRT] [I] Total Activation Memory: 161156608
[05/22/2024-17:57:18] [TRT] [I] Total Weights Memory: 85935104
[05/22/2024-17:57:18] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2836, GPU 946 (MiB)
[05/22/2024-17:57:18] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[05/22/2024-17:57:18] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[05/22/2024-17:57:18] [TRT] [W] Check verbose logs for the list of affected weights.
[05/22/2024-17:57:18] [TRT] [W] - 9 weights are affected by this issue: Detected subnormal FP16 values.
[05/22/2024-17:57:18] [TRT] [W] - 5 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.
[05/22/2024-17:57:18] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 438 MiB
[05/22/2024-17:57:18] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +81, GPU +82, now: CPU 81, GPU 82 (MiB)
[05/22/2024-17:57:18] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/22/2024-17:57:19] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2753, GPU 838 (MiB)
[05/22/2024-17:57:19] [TRT] [I] Graph optimization time: 0.000263448 seconds.
[05/22/2024-17:57:19] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2760, GPU 848 (MiB)
[05/22/2024-17:57:19] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2760, GPU 856 (MiB)
[05/22/2024-17:57:19] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/22/2024-17:57:20] [TRT] [I] Detected 3 inputs and 3 output network tensors.
[05/22/2024-17:57:20] [TRT] [I] Total Host Persistent Memory: 368
[05/22/2024-17:57:20] [TRT] [I] Total Device Persistent Memory: 0
[05/22/2024-17:57:20] [TRT] [I] Total Scratch Memory: 716800
[05/22/2024-17:57:20] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 2 steps to complete.
[05/22/2024-17:57:20] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.005941ms to assign 2 blocks to 2 nodes requiring 768000 bytes.
[05/22/2024-17:57:20] [TRT] [I] Total Activation Memory: 768000
[05/22/2024-17:57:20] [TRT] [I] Total Weights Memory: 18584
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2768, GPU 868 (MiB)
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2768, GPU 876 (MiB)
[05/22/2024-17:57:20] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 438 MiB
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[05/22/2024-17:57:20] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2767, GPU 840 (MiB)
[05/22/2024-17:57:20] [TRT] [I] Graph optimization time: 0.000197363 seconds.
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +10, now: CPU 2768, GPU 850 (MiB)
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2768, GPU 858 (MiB)
[05/22/2024-17:57:20] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/22/2024-17:57:20] [TRT] [I] Detected 7 inputs and 3 output network tensors.
[05/22/2024-17:57:20] [TRT] [I] Total Host Persistent Memory: 560
[05/22/2024-17:57:20] [TRT] [I] Total Device Persistent Memory: 0
[05/22/2024-17:57:20] [TRT] [I] Total Scratch Memory: 0
[05/22/2024-17:57:20] [TRT] [I] Total Activation Memory: 0
[05/22/2024-17:57:20] [TRT] [I] Total Weights Memory: 0
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2768, GPU 866 (MiB)
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2768, GPU 874 (MiB)
[05/22/2024-17:57:20] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 438 MiB
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[05/22/2024-17:57:20] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2767, GPU 840 (MiB)
[05/22/2024-17:57:20] [TRT] [I] Graph optimization time: 0.000142058 seconds.
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +10, now: CPU 2768, GPU 850 (MiB)
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2768, GPU 858 (MiB)
[05/22/2024-17:57:20] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/22/2024-17:57:20] [TRT] [I] Detected 2 inputs and 1 output network tensors.
[05/22/2024-17:57:20] [TRT] [I] Total Host Persistent Memory: 32
[05/22/2024-17:57:20] [TRT] [I] Total Device Persistent Memory: 0
[05/22/2024-17:57:20] [TRT] [I] Total Scratch Memory: 0
[05/22/2024-17:57:20] [TRT] [I] Total Activation Memory: 0
[05/22/2024-17:57:20] [TRT] [I] Total Weights Memory: 8
[05/22/2024-17:57:20] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 438 MiB
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[05/22/2024-17:57:20] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/22/2024-17:57:20] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2768, GPU 840 (MiB)
[05/22/2024-17:57:21] [TRT] [I] Graph optimization time: 0.000108432 seconds.
[05/22/2024-17:57:21] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2770, GPU 850 (MiB)
[05/22/2024-17:57:21] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2770, GPU 858 (MiB)
[05/22/2024-17:57:21] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/22/2024-17:57:24] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[05/22/2024-17:57:24] [TRT] [I] Total Host Persistent Memory: 7648
[05/22/2024-17:57:24] [TRT] [I] Total Device Persistent Memory: 0
[05/22/2024-17:57:24] [TRT] [I] Total Scratch Memory: 0
[05/22/2024-17:57:24] [TRT] [I] Total Activation Memory: 0
[05/22/2024-17:57:24] [TRT] [I] Total Weights Memory: 1049600
[05/22/2024-17:57:24] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 438 MiB
[05/22/2024-17:57:24] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +2, now: CPU 0, GPU 2 (MiB)
[05/22/2024-17:57:24] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/22/2024-17:57:24] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2885, GPU 840 (MiB)
[05/22/2024-17:57:24] [TRT] [I] Graph optimization time: 0.000102385 seconds.
[05/22/2024-17:57:24] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2886, GPU 850 (MiB)
[05/22/2024-17:57:24] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2886, GPU 858 (MiB)
[05/22/2024-17:57:24] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/22/2024-17:57:25] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[05/22/2024-17:57:25] [TRT] [I] Total Host Persistent Memory: 7648
[05/22/2024-17:57:25] [TRT] [I] Total Device Persistent Memory: 0
[05/22/2024-17:57:25] [TRT] [I] Total Scratch Memory: 0
[05/22/2024-17:57:25] [TRT] [I] Total Activation Memory: 0
[05/22/2024-17:57:25] [TRT] [I] Total Weights Memory: 327680
[05/22/2024-17:57:25] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 438 MiB
[05/22/2024-17:57:25] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[05/22/2024-17:57:25] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/22/2024-17:57:25] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2885, GPU 840 (MiB)
[05/22/2024-17:57:25] [TRT] [I] Graph optimization time: 0.000243978 seconds.
[05/22/2024-17:57:25] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +10, now: CPU 2886, GPU 850 (MiB)
[05/22/2024-17:57:25] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2886, GPU 858 (MiB)
[05/22/2024-17:57:25] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/22/2024-17:57:52] [TRT] [I] Detected 2 inputs and 1 output network tensors.
[05/22/2024-17:57:52] [TRT] [I] Total Host Persistent Memory: 8000
[05/22/2024-17:57:52] [TRT] [I] Total Device Persistent Memory: 0
[05/22/2024-17:57:52] [TRT] [I] Total Scratch Memory: 2560
[05/22/2024-17:57:52] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 7 steps to complete.
[05/22/2024-17:57:52] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.017882ms to assign 3 blocks to 7 nodes requiring 87552 bytes.
[05/22/2024-17:57:52] [TRT] [I] Total Activation Memory: 87552
[05/22/2024-17:57:52] [TRT] [I] Total Weights Memory: 32832
[05/22/2024-17:57:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 438 MiB
[05/22/2024-17:57:52] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[05/22/2024-17:57:52] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
Loading TensorRT plugin from build/plugins/RNNTOptPlugin/librnntoptplugin.so
Initializing DALI with parameters:
	        __class__ : <class 'code.rnnt.dali.pipeline.DALIInferencePipeline'>
	 audio_fp16_input : True
	       batch_size : 16
	           device : gpu
	        device_id : 0
	           dither : 1e-05
	   frame_splicing : 3
	         highfreq : 0
	              log : True
	          lowfreq : 0
	     max_duration : 16.7
	            n_fft : 512
	            nfilt : 80
	        normalize : per_feature
	      num_threads : 2
	           pad_to : 8
	          preemph : 0.97
	processing_layout : tf
	   resample_range : None
	      sample_rate : 16000
	             self : <code.rnnt.dali.pipeline.DALIInferencePipeline object at 0x7f1a3ce3c520>
	    total_samples : 16
	           window : hann
	      window_size : 0.02
	    window_stride : 0.01
self.n_fft = 512
self.hop_length = 160
self.win_length = 320
self.window_tensor = tensor([0.0000e+00, 9.6977e-05, 3.8791e-04, 8.7264e-04, 1.5510e-03, 2.4227e-03,
        3.4875e-03, 4.7449e-03, 6.1944e-03, 7.8355e-03, 9.6675e-03, 1.1690e-02,
        1.3901e-02, 1.6302e-02, 1.8890e-02, 2.1664e-02, 2.4624e-02, 2.7769e-02,
        3.1096e-02, 3.4606e-02, 3.8296e-02, 4.2165e-02, 4.6212e-02, 5.0435e-02,
        5.4833e-02, 5.9403e-02, 6.4144e-02, 6.9054e-02, 7.4131e-02, 7.9373e-02,
        8.4779e-02, 9.0346e-02, 9.6071e-02, 1.0195e-01, 1.0799e-01, 1.1418e-01,
        1.2052e-01, 1.2700e-01, 1.3363e-01, 1.4041e-01, 1.4732e-01, 1.5437e-01,
        1.6155e-01, 1.6886e-01, 1.7631e-01, 1.8388e-01, 1.9157e-01, 1.9938e-01,
        2.0730e-01, 2.1534e-01, 2.2350e-01, 2.3175e-01, 2.4012e-01, 2.4858e-01,
        2.5714e-01, 2.6580e-01, 2.7454e-01, 2.8338e-01, 2.9229e-01, 3.0129e-01,
        3.1037e-01, 3.1951e-01, 3.2873e-01, 3.3802e-01, 3.4737e-01, 3.5677e-01,
        3.6624e-01, 3.7575e-01, 3.8531e-01, 3.9492e-01, 4.0457e-01, 4.1425e-01,
        4.2397e-01, 4.3372e-01, 4.4349e-01, 4.5329e-01, 4.6310e-01, 4.7293e-01,
        4.8277e-01, 4.9261e-01, 5.0246e-01, 5.1231e-01, 5.2215e-01, 5.3198e-01,
        5.4181e-01, 5.5161e-01, 5.6140e-01, 5.7116e-01, 5.8089e-01, 5.9059e-01,
        6.0026e-01, 6.0989e-01, 6.1947e-01, 6.2901e-01, 6.3850e-01, 6.4794e-01,
        6.5732e-01, 6.6663e-01, 6.7588e-01, 6.8507e-01, 6.9418e-01, 7.0322e-01,
        7.1218e-01, 7.2105e-01, 7.2984e-01, 7.3854e-01, 7.4715e-01, 7.5566e-01,
        7.6408e-01, 7.7239e-01, 7.8059e-01, 7.8869e-01, 7.9667e-01, 8.0454e-01,
        8.1229e-01, 8.1992e-01, 8.2743e-01, 8.3481e-01, 8.4206e-01, 8.4917e-01,
        8.5616e-01, 8.6300e-01, 8.6970e-01, 8.7626e-01, 8.8267e-01, 8.8893e-01,
        8.9505e-01, 9.0101e-01, 9.0681e-01, 9.1246e-01, 9.1794e-01, 9.2327e-01,
        9.2843e-01, 9.3342e-01, 9.3825e-01, 9.4290e-01, 9.4739e-01, 9.5170e-01,
        9.5583e-01, 9.5979e-01, 9.6357e-01, 9.6717e-01, 9.7059e-01, 9.7383e-01,
        9.7688e-01, 9.7975e-01, 9.8243e-01, 9.8492e-01, 9.8723e-01, 9.8935e-01,
        9.9127e-01, 9.9301e-01, 9.9455e-01, 9.9591e-01, 9.9707e-01, 9.9804e-01,
        9.9881e-01, 9.9939e-01, 9.9978e-01, 9.9998e-01, 9.9998e-01, 9.9978e-01,
        9.9939e-01, 9.9881e-01, 9.9804e-01, 9.9707e-01, 9.9591e-01, 9.9455e-01,
        9.9301e-01, 9.9127e-01, 9.8935e-01, 9.8723e-01, 9.8492e-01, 9.8243e-01,
        9.7975e-01, 9.7688e-01, 9.7383e-01, 9.7059e-01, 9.6717e-01, 9.6357e-01,
        9.5979e-01, 9.5583e-01, 9.5170e-01, 9.4739e-01, 9.4290e-01, 9.3825e-01,
        9.3342e-01, 9.2843e-01, 9.2327e-01, 9.1794e-01, 9.1246e-01, 9.0681e-01,
        9.0101e-01, 8.9505e-01, 8.8893e-01, 8.8267e-01, 8.7626e-01, 8.6970e-01,
        8.6300e-01, 8.5616e-01, 8.4917e-01, 8.4206e-01, 8.3481e-01, 8.2743e-01,
        8.1992e-01, 8.1229e-01, 8.0454e-01, 7.9667e-01, 7.8869e-01, 7.8059e-01,
        7.7239e-01, 7.6408e-01, 7.5566e-01, 7.4715e-01, 7.3854e-01, 7.2984e-01,
        7.2105e-01, 7.1218e-01, 7.0322e-01, 6.9418e-01, 6.8507e-01, 6.7589e-01,
        6.6663e-01, 6.5732e-01, 6.4794e-01, 6.3850e-01, 6.2901e-01, 6.1947e-01,
        6.0989e-01, 6.0026e-01, 5.9059e-01, 5.8089e-01, 5.7116e-01, 5.6140e-01,
        5.5161e-01, 5.4181e-01, 5.3198e-01, 5.2215e-01, 5.1231e-01, 5.0246e-01,
        4.9261e-01, 4.8277e-01, 4.7293e-01, 4.6310e-01, 4.5329e-01, 4.4349e-01,
        4.3372e-01, 4.2397e-01, 4.1425e-01, 4.0457e-01, 3.9492e-01, 3.8531e-01,
        3.7575e-01, 3.6624e-01, 3.5677e-01, 3.4737e-01, 3.3802e-01, 3.2873e-01,
        3.1951e-01, 3.1037e-01, 3.0129e-01, 2.9229e-01, 2.8338e-01, 2.7454e-01,
        2.6580e-01, 2.5714e-01, 2.4858e-01, 2.4012e-01, 2.3175e-01, 2.2350e-01,
        2.1534e-01, 2.0730e-01, 1.9938e-01, 1.9157e-01, 1.8388e-01, 1.7631e-01,
        1.6886e-01, 1.6155e-01, 1.5437e-01, 1.4732e-01, 1.4041e-01, 1.3363e-01,
        1.2700e-01, 1.2052e-01, 1.1418e-01, 1.0799e-01, 1.0195e-01, 9.6071e-02,
        9.0346e-02, 8.4779e-02, 7.9373e-02, 7.4131e-02, 6.9054e-02, 6.4144e-02,
        5.9403e-02, 5.4833e-02, 5.0435e-02, 4.6212e-02, 4.2165e-02, 3.8296e-02,
        3.4606e-02, 3.1096e-02, 2.7769e-02, 2.4624e-02, 2.1664e-02, 1.8889e-02,
        1.6302e-02, 1.3901e-02, 1.1690e-02, 9.6675e-03, 7.8355e-03, 6.1944e-03,
        4.7449e-03, 3.4875e-03, 2.4227e-03, 1.5510e-03, 8.7264e-04, 3.8791e-04,
        9.6977e-05, 2.9802e-08])
self.sample_rate = 16000
self.window_size = 0.02
self.window_stride = 0.01
self.lowfreq = 0
self.device = gpu
Time taken to generate engines: 44.627591371536255 seconds
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
[2024-05-22 17:58:05,987 main.py:230 INFO] Detected system ID: KnownSystem.ocejon
[2024-05-22 17:58:06,219 harness.py:236 INFO] The harness will load 1 plugins: ['build/plugins/RNNTOptPlugin/librnntoptplugin.so']
[2024-05-22 17:58:06,234 generate_conf_files.py:107 INFO] Generated measurements/ entries for ocejon_TRT/rnnt/Offline
[2024-05-22 17:58:06,235 __init__.py:46 INFO] Running command: ./build/bin/harness_rnnt --plugins="build/plugins/RNNTOptPlugin/librnntoptplugin.so" --logfile_outdir="/work/build/logs/2024.05.22-17.56.54/ocejon_TRT/rnnt/Offline" --logfile_prefix="mlperf_log_" --performance_sample_count=2513 --audio_batch_size=64 --audio_buffer_num_lines=1024 --dali_batches_issue_ahead=4 --dali_pipeline_depth=4 --disable_encoder_plugin=true --num_warmups=2048 --mlperf_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/Offline/mlperf.conf" --user_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/Offline/user.conf" --batch_size=80 --cuda_graph=true --pipelined_execution=true --batch_sorting=true --enable_audio_processing=true --use_copy_kernel=true --streams_per_gpu=1 --audio_fp16_input=true --start_from_device=false --audio_serialized_pipeline_file="build/bin/dali/dali_pipeline_gpu_fp16.pth" --scenario Offline --model rnnt --engine_dir="./build/engines/ocejon/rnnt/Offline"
[2024-05-22 17:58:06,235 __init__.py:53 INFO] Overriding Environment
audio_batch_size : 64
audio_buffer_num_lines : 1024
benchmark : Benchmark.RNNT
buffer_manager_thread_count : 0
dali_batches_issue_ahead : 4
dali_pipeline_depth : 4
data_dir : /scratch/gonisla//data
disable_encoder_plugin : True
gpu_batch_size : 80
gpu_copy_streams : 4
gpu_inference_streams : 1
input_dtype : fp16
input_format : linear
log_dir : /work/build/logs/2024.05.22-17.56.54
map_path : data_maps/rnnt_dev_clean_512/val_map.txt
num_warmups : 2048
offline_expected_qps : 2500.0
precision : fp16
preprocessed_data_dir : /scratch/gonisla//preprocessed_data
scenario : Scenario.Offline
system : SystemConfiguration(host_cpu_conf=CPUConfiguration(layout={CPU(name='Intel(R) Xeon(R) Silver 4314 CPU @ 2.40GHz', architecture=<CPUArchitecture.x86_64: AliasedName(name='x86_64', aliases=(), patterns=())>, core_count=16, threads_per_core=1): 1}), host_mem_conf=MemoryConfiguration(host_memory_capacity=Memory(quantity=65.551536, byte_suffix=<ByteSuffix.GB: (1000, 3)>, _num_bytes=65551536000), comparison_tolerance=0.05), accelerator_conf=AcceleratorConfiguration(layout=defaultdict(<class 'int'>, {GPU(name='NVIDIA A30', accelerator_type=<AcceleratorType.Discrete: AliasedName(name='Discrete', aliases=(), patterns=())>, vram=Memory(quantity=24.0, byte_suffix=<ByteSuffix.GiB: (1024, 3)>, _num_bytes=25769803776), max_power_limit=165.0, pci_id='0x20B710DE', compute_sm=80): 1})), numa_conf=None, system_id='ocejon')
tensor_path : build/preprocessed_data/rnnt_dev_clean_512/fp16
use_graphs : True
system_id : ocejon
config_name : ocejon_rnnt_Offline
workload_setting : WorkloadSetting(HarnessType.Custom, AccuracyTarget.k_99, PowerSetting.MaxP)
optimization_level : plugin-enabled
use_cpu : False
use_inferentia : False
num_profiles : 4
config_ver : custom_k_99_MaxP
accuracy_level : 99%
inference_server : custom
skip_file_checks : False
power_limit : None
cpu_freq : None
<class 'ctypes.CDLL'>
<_FuncPtr object at 0x7f62febbddc0>
server_ip b''
port 0
server_ip b'127.0.0.1'
port 6526
&&&& RUNNING RNN-T_Harness # ./build/bin/harness_rnnt
I0522 17:58:06.297789 100871 main_rnnt.cc:2903] Found 1 GPUs
[I] Starting creating QSL.
[I] Finished creating QSL.
[I] Starting creating SUT.
[I] Set to device 0
Dali pipeline creating..
Dali pipeline created
[I] Creating stream 0/1
[I] [TRT] Loaded engine size: 81 MiB
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +8, GPU +12, now: CPU 129, GPU 1128 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +81, now: CPU 0, GPU 81 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 129, GPU 1128 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +154, now: CPU 0, GPU 235 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntEncoder runner: encoder
[I] [TRT] Loaded engine size: 3 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 53, GPU 1290 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 54, GPU 1300 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 235 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 54, GPU 1304 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 54, GPU 1312 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1, now: CPU 0, GPU 236 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntDecoder runner: decoder
[I] [TRT] Loaded engine size: 1 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +1, now: CPU 0, GPU 237 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 237 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointFc1 runner: fc1_a
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 237 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 237 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointFc1 runner: fc1_b
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 237 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 237 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointBackend runner: joint_backend
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 55, GPU 1322 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +12, now: CPU 56, GPU 1334 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 237 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +8, now: CPU 56, GPU 1326 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 56, GPU 1334 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 237 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntIsel runner: isel
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 237 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 237 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntIgather runner: igather
[I] Instantiated RnntEngineContainer runner
cudaMemcpy blocking 
cudaMemcpy blocking 
[I] Instantiated RnntTensorContainer host memory
Stream::Stream sampleSize: 61440
Stream::Stream singleSampleSize: 480
Stream::Stream fullseqSampleSize: 61440
Stream::Stream mBatchSize: 80
[I] Finished creating SUT.
[I] Starting warming up SUT.
[I] Finished warming up SUT.
[I] Starting running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : RNNT SERVER
Scenario : Offline
Mode     : PerformanceOnly
Samples per second: 2381.64
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes

================================================
Additional Stats
================================================
Min latency (ns)                : 421145647
Max latency (ns)                : 692799567401
Mean latency (ns)               : 437567078486
50.00 percentile latency (ns)   : 474007969870
90.00 percentile latency (ns)   : 669437356808
95.00 percentile latency (ns)   : 682205654158
97.00 percentile latency (ns)   : 686805773737
99.00 percentile latency (ns)   : 691019501790
99.90 percentile latency (ns)   : 692658306482

================================================
Test Parameters Used
================================================
samples_per_query : 1650000
target_qps : 2500
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 1
max_query_count : 0
qsl_rng_seed : 148687905518835231
sample_index_rng_seed : 520418551913322573
schedule_rng_seed : 811580660758947900
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
accuracy_log_sampling_target : 0
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 2513

No warnings encountered during test.

No errors encountered during test.
[I] Finished running actual test.
&&&& PASSED RNN-T_Harness # ./build/bin/harness_rnnt
[2024-05-22 18:09:45,100 run_harness.py:347 INFO] Result: result_samples_per_second: 2381.64, Result is VALID
127.0.0.1, 127.0.0.1, 9
6526
- > NVMLDevice
Agg. - > 0
Int. - > 0
Lines - > @
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
- > 127.0.0.1
- > 6526
 
======================== Result summaries: ========================

 ocejon_TRT-custom_k_99_MaxP-Offline:
   rnnt:
     performance: result_samples_per_second: 2381.64, Result is VALID
 

======================== Extra Perf Stats: ========================

 ocejon_TRT-custom_k_99_MaxP-Offline:
    FileNotFoundError: Cannot find perf logs for ocejon_TRT/rnnt/Offline at build/artifacts/closed/NVIDIA/results/ocejon_TRT/rnnt/Offline/performance/run_1. Non-NVIDIA users ignore this. NVIDIA users run `make pull_artifacts_repo`.
make[1]: Leaving directory '/work'
