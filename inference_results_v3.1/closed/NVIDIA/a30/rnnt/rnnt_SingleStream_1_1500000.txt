$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
make[1]: Entering directory '/work'
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
[04/10/2024-21:43:14] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 126, GPU 480 (MiB)
[04/10/2024-21:43:22] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1957, GPU +346, now: CPU 2188, GPU 826 (MiB)
[04/10/2024-21:43:22] [TRT] [I] Graph optimization time: 0.000322619 seconds.
[04/10/2024-21:43:22] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +10, now: CPU 2532, GPU 836 (MiB)
[04/10/2024-21:43:22] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2533, GPU 846 (MiB)
[04/10/2024-21:43:22] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/10/2024-21:43:23] [TRT] [I] Detected 6 inputs and 5 output network tensors.
[04/10/2024-21:43:23] [TRT] [I] Total Host Persistent Memory: 3648
[04/10/2024-21:43:23] [TRT] [I] Total Device Persistent Memory: 4096
[04/10/2024-21:43:23] [TRT] [I] Total Scratch Memory: 59700512
[04/10/2024-21:43:23] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 7 steps to complete.
[04/10/2024-21:43:23] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.028215ms to assign 4 blocks to 7 nodes requiring 59963904 bytes.
[04/10/2024-21:43:23] [TRT] [I] Total Activation Memory: 59963392
[04/10/2024-21:43:23] [TRT] [I] Total Weights Memory: 85935104
[04/10/2024-21:43:23] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2863, GPU 946 (MiB)
[04/10/2024-21:43:23] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[04/10/2024-21:43:23] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[04/10/2024-21:43:23] [TRT] [W] Check verbose logs for the list of affected weights.
[04/10/2024-21:43:23] [TRT] [W] - 9 weights are affected by this issue: Detected subnormal FP16 values.
[04/10/2024-21:43:23] [TRT] [W] - 5 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.
[04/10/2024-21:43:23] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[04/10/2024-21:43:23] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +81, GPU +82, now: CPU 81, GPU 82 (MiB)
[04/10/2024-21:43:23] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/10/2024-21:43:24] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2781, GPU 838 (MiB)
[04/10/2024-21:43:24] [TRT] [I] Graph optimization time: 0.000259487 seconds.
[04/10/2024-21:43:24] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2787, GPU 848 (MiB)
[04/10/2024-21:43:24] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2787, GPU 856 (MiB)
[04/10/2024-21:43:24] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/10/2024-21:43:25] [TRT] [I] Detected 3 inputs and 3 output network tensors.
[04/10/2024-21:43:25] [TRT] [I] Total Host Persistent Memory: 368
[04/10/2024-21:43:25] [TRT] [I] Total Device Persistent Memory: 0
[04/10/2024-21:43:25] [TRT] [I] Total Scratch Memory: 8960
[04/10/2024-21:43:25] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 2 steps to complete.
[04/10/2024-21:43:25] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.005137ms to assign 2 blocks to 2 nodes requiring 10240 bytes.
[04/10/2024-21:43:25] [TRT] [I] Total Activation Memory: 10240
[04/10/2024-21:43:25] [TRT] [I] Total Weights Memory: 18584
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2797, GPU 868 (MiB)
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2797, GPU 876 (MiB)
[04/10/2024-21:43:25] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[04/10/2024-21:43:25] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2796, GPU 840 (MiB)
[04/10/2024-21:43:25] [TRT] [I] Graph optimization time: 0.000187814 seconds.
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2797, GPU 850 (MiB)
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2797, GPU 858 (MiB)
[04/10/2024-21:43:25] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/10/2024-21:43:25] [TRT] [I] Detected 7 inputs and 3 output network tensors.
[04/10/2024-21:43:25] [TRT] [I] Total Host Persistent Memory: 560
[04/10/2024-21:43:25] [TRT] [I] Total Device Persistent Memory: 0
[04/10/2024-21:43:25] [TRT] [I] Total Scratch Memory: 0
[04/10/2024-21:43:25] [TRT] [I] Total Activation Memory: 0
[04/10/2024-21:43:25] [TRT] [I] Total Weights Memory: 0
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2797, GPU 866 (MiB)
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2797, GPU 874 (MiB)
[04/10/2024-21:43:25] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[04/10/2024-21:43:25] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2796, GPU 840 (MiB)
[04/10/2024-21:43:25] [TRT] [I] Graph optimization time: 0.000132294 seconds.
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2797, GPU 850 (MiB)
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2797, GPU 858 (MiB)
[04/10/2024-21:43:25] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/10/2024-21:43:25] [TRT] [I] Detected 2 inputs and 1 output network tensors.
[04/10/2024-21:43:25] [TRT] [I] Total Host Persistent Memory: 32
[04/10/2024-21:43:25] [TRT] [I] Total Device Persistent Memory: 0
[04/10/2024-21:43:25] [TRT] [I] Total Scratch Memory: 0
[04/10/2024-21:43:25] [TRT] [I] Total Activation Memory: 0
[04/10/2024-21:43:25] [TRT] [I] Total Weights Memory: 8
[04/10/2024-21:43:25] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[04/10/2024-21:43:25] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/10/2024-21:43:25] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2797, GPU 840 (MiB)
[04/10/2024-21:43:26] [TRT] [I] Graph optimization time: 0.000107245 seconds.
[04/10/2024-21:43:26] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2799, GPU 850 (MiB)
[04/10/2024-21:43:26] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2799, GPU 858 (MiB)
[04/10/2024-21:43:26] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/10/2024-21:43:28] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[04/10/2024-21:43:28] [TRT] [I] Total Host Persistent Memory: 7328
[04/10/2024-21:43:28] [TRT] [I] Total Device Persistent Memory: 0
[04/10/2024-21:43:28] [TRT] [I] Total Scratch Memory: 0
[04/10/2024-21:43:28] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 2 steps to complete.
[04/10/2024-21:43:28] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.00401ms to assign 2 blocks to 2 nodes requiring 1024 bytes.
[04/10/2024-21:43:28] [TRT] [I] Total Activation Memory: 1024
[04/10/2024-21:43:28] [TRT] [I] Total Weights Memory: 1049600
[04/10/2024-21:43:28] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[04/10/2024-21:43:28] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +2, now: CPU 0, GPU 2 (MiB)
[04/10/2024-21:43:28] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/10/2024-21:43:28] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2903, GPU 840 (MiB)
[04/10/2024-21:43:28] [TRT] [I] Graph optimization time: 9.0354e-05 seconds.
[04/10/2024-21:43:28] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2904, GPU 850 (MiB)
[04/10/2024-21:43:28] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2904, GPU 858 (MiB)
[04/10/2024-21:43:28] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/10/2024-21:43:29] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[04/10/2024-21:43:29] [TRT] [I] Total Host Persistent Memory: 7328
[04/10/2024-21:43:29] [TRT] [I] Total Device Persistent Memory: 0
[04/10/2024-21:43:29] [TRT] [I] Total Scratch Memory: 0
[04/10/2024-21:43:29] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 2 steps to complete.
[04/10/2024-21:43:29] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.003835ms to assign 2 blocks to 2 nodes requiring 1024 bytes.
[04/10/2024-21:43:29] [TRT] [I] Total Activation Memory: 1024
[04/10/2024-21:43:29] [TRT] [I] Total Weights Memory: 327680
[04/10/2024-21:43:29] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[04/10/2024-21:43:29] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[04/10/2024-21:43:29] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[04/10/2024-21:43:29] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2913, GPU 840 (MiB)
[04/10/2024-21:43:29] [TRT] [I] Graph optimization time: 0.000235293 seconds.
[04/10/2024-21:43:29] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2913, GPU 850 (MiB)
[04/10/2024-21:43:29] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2913, GPU 858 (MiB)
[04/10/2024-21:43:29] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/10/2024-21:43:39] [TRT] [I] Detected 2 inputs and 1 output network tensors.
[04/10/2024-21:43:39] [TRT] [I] Total Host Persistent Memory: 7680
[04/10/2024-21:43:39] [TRT] [I] Total Device Persistent Memory: 0
[04/10/2024-21:43:39] [TRT] [I] Total Scratch Memory: 32
[04/10/2024-21:43:39] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 5 steps to complete.
[04/10/2024-21:43:39] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.010674ms to assign 3 blocks to 5 nodes requiring 2048 bytes.
[04/10/2024-21:43:39] [TRT] [I] Total Activation Memory: 2048
[04/10/2024-21:43:39] [TRT] [I] Total Weights Memory: 29754
[04/10/2024-21:43:39] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[04/10/2024-21:43:39] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[04/10/2024-21:43:39] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
Loading TensorRT plugin from build/plugins/RNNTOptPlugin/librnntoptplugin.so
Initializing DALI with parameters:
	        __class__ : <class 'code.rnnt.dali.pipeline.DALIInferencePipeline'>
	 audio_fp16_input : True
	       batch_size : 16
	           device : gpu
	        device_id : 0
	           dither : 1e-05
	   frame_splicing : 3
	         highfreq : 0
	              log : True
	          lowfreq : 0
	     max_duration : 16.7
	            n_fft : 512
	            nfilt : 80
	        normalize : per_feature
	      num_threads : 2
	           pad_to : 8
	          preemph : 0.97
	processing_layout : tf
	   resample_range : None
	      sample_rate : 16000
	             self : <code.rnnt.dali.pipeline.DALIInferencePipeline object at 0x7ff4f6217220>
	    total_samples : 16
	           window : hann
	      window_size : 0.02
	    window_stride : 0.01
self.n_fft = 512
self.hop_length = 160
self.win_length = 320
self.window_tensor = tensor([0.0000e+00, 9.6977e-05, 3.8791e-04, 8.7264e-04, 1.5510e-03, 2.4227e-03,
        3.4875e-03, 4.7449e-03, 6.1944e-03, 7.8355e-03, 9.6675e-03, 1.1690e-02,
        1.3901e-02, 1.6302e-02, 1.8890e-02, 2.1664e-02, 2.4624e-02, 2.7769e-02,
        3.1096e-02, 3.4606e-02, 3.8296e-02, 4.2165e-02, 4.6212e-02, 5.0435e-02,
        5.4833e-02, 5.9403e-02, 6.4144e-02, 6.9054e-02, 7.4131e-02, 7.9373e-02,
        8.4779e-02, 9.0346e-02, 9.6071e-02, 1.0195e-01, 1.0799e-01, 1.1418e-01,
        1.2052e-01, 1.2700e-01, 1.3363e-01, 1.4041e-01, 1.4732e-01, 1.5437e-01,
        1.6155e-01, 1.6886e-01, 1.7631e-01, 1.8388e-01, 1.9157e-01, 1.9938e-01,
        2.0730e-01, 2.1534e-01, 2.2350e-01, 2.3175e-01, 2.4012e-01, 2.4858e-01,
        2.5714e-01, 2.6580e-01, 2.7454e-01, 2.8338e-01, 2.9229e-01, 3.0129e-01,
        3.1037e-01, 3.1951e-01, 3.2873e-01, 3.3802e-01, 3.4737e-01, 3.5677e-01,
        3.6624e-01, 3.7575e-01, 3.8531e-01, 3.9492e-01, 4.0457e-01, 4.1425e-01,
        4.2397e-01, 4.3372e-01, 4.4349e-01, 4.5329e-01, 4.6310e-01, 4.7293e-01,
        4.8277e-01, 4.9261e-01, 5.0246e-01, 5.1231e-01, 5.2215e-01, 5.3198e-01,
        5.4181e-01, 5.5161e-01, 5.6140e-01, 5.7116e-01, 5.8089e-01, 5.9059e-01,
        6.0026e-01, 6.0989e-01, 6.1947e-01, 6.2901e-01, 6.3850e-01, 6.4794e-01,
        6.5732e-01, 6.6663e-01, 6.7588e-01, 6.8507e-01, 6.9418e-01, 7.0322e-01,
        7.1218e-01, 7.2105e-01, 7.2984e-01, 7.3854e-01, 7.4715e-01, 7.5566e-01,
        7.6408e-01, 7.7239e-01, 7.8059e-01, 7.8869e-01, 7.9667e-01, 8.0454e-01,
        8.1229e-01, 8.1992e-01, 8.2743e-01, 8.3481e-01, 8.4206e-01, 8.4917e-01,
        8.5616e-01, 8.6300e-01, 8.6970e-01, 8.7626e-01, 8.8267e-01, 8.8893e-01,
        8.9505e-01, 9.0101e-01, 9.0681e-01, 9.1246e-01, 9.1794e-01, 9.2327e-01,
        9.2843e-01, 9.3342e-01, 9.3825e-01, 9.4290e-01, 9.4739e-01, 9.5170e-01,
        9.5583e-01, 9.5979e-01, 9.6357e-01, 9.6717e-01, 9.7059e-01, 9.7383e-01,
        9.7688e-01, 9.7975e-01, 9.8243e-01, 9.8492e-01, 9.8723e-01, 9.8935e-01,
        9.9127e-01, 9.9301e-01, 9.9455e-01, 9.9591e-01, 9.9707e-01, 9.9804e-01,
        9.9881e-01, 9.9939e-01, 9.9978e-01, 9.9998e-01, 9.9998e-01, 9.9978e-01,
        9.9939e-01, 9.9881e-01, 9.9804e-01, 9.9707e-01, 9.9591e-01, 9.9455e-01,
        9.9301e-01, 9.9127e-01, 9.8935e-01, 9.8723e-01, 9.8492e-01, 9.8243e-01,
        9.7975e-01, 9.7688e-01, 9.7383e-01, 9.7059e-01, 9.6717e-01, 9.6357e-01,
        9.5979e-01, 9.5583e-01, 9.5170e-01, 9.4739e-01, 9.4290e-01, 9.3825e-01,
        9.3342e-01, 9.2843e-01, 9.2327e-01, 9.1794e-01, 9.1246e-01, 9.0681e-01,
        9.0101e-01, 8.9505e-01, 8.8893e-01, 8.8267e-01, 8.7626e-01, 8.6970e-01,
        8.6300e-01, 8.5616e-01, 8.4917e-01, 8.4206e-01, 8.3481e-01, 8.2743e-01,
        8.1992e-01, 8.1229e-01, 8.0454e-01, 7.9667e-01, 7.8869e-01, 7.8059e-01,
        7.7239e-01, 7.6408e-01, 7.5566e-01, 7.4715e-01, 7.3854e-01, 7.2984e-01,
        7.2105e-01, 7.1218e-01, 7.0322e-01, 6.9418e-01, 6.8507e-01, 6.7589e-01,
        6.6663e-01, 6.5732e-01, 6.4794e-01, 6.3850e-01, 6.2901e-01, 6.1947e-01,
        6.0989e-01, 6.0026e-01, 5.9059e-01, 5.8089e-01, 5.7116e-01, 5.6140e-01,
        5.5161e-01, 5.4181e-01, 5.3198e-01, 5.2215e-01, 5.1231e-01, 5.0246e-01,
        4.9261e-01, 4.8277e-01, 4.7293e-01, 4.6310e-01, 4.5329e-01, 4.4349e-01,
        4.3372e-01, 4.2397e-01, 4.1425e-01, 4.0457e-01, 3.9492e-01, 3.8531e-01,
        3.7575e-01, 3.6624e-01, 3.5677e-01, 3.4737e-01, 3.3802e-01, 3.2873e-01,
        3.1951e-01, 3.1037e-01, 3.0129e-01, 2.9229e-01, 2.8338e-01, 2.7454e-01,
        2.6580e-01, 2.5714e-01, 2.4858e-01, 2.4012e-01, 2.3175e-01, 2.2350e-01,
        2.1534e-01, 2.0730e-01, 1.9938e-01, 1.9157e-01, 1.8388e-01, 1.7631e-01,
        1.6886e-01, 1.6155e-01, 1.5437e-01, 1.4732e-01, 1.4041e-01, 1.3363e-01,
        1.2700e-01, 1.2052e-01, 1.1418e-01, 1.0799e-01, 1.0195e-01, 9.6071e-02,
        9.0346e-02, 8.4779e-02, 7.9373e-02, 7.4131e-02, 6.9054e-02, 6.4144e-02,
        5.9403e-02, 5.4833e-02, 5.0435e-02, 4.6212e-02, 4.2165e-02, 3.8296e-02,
        3.4606e-02, 3.1096e-02, 2.7769e-02, 2.4624e-02, 2.1664e-02, 1.8889e-02,
        1.6302e-02, 1.3901e-02, 1.1690e-02, 9.6675e-03, 7.8355e-03, 6.1944e-03,
        4.7449e-03, 3.4875e-03, 2.4227e-03, 1.5510e-03, 8.7264e-04, 3.8791e-04,
        9.6977e-05, 2.9802e-08])
self.sample_rate = 16000
self.window_size = 0.02
self.window_stride = 0.01
self.lowfreq = 0
self.device = gpu
Time taken to generate engines: 25.630754470825195 seconds
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
[2024-04-10 21:43:51,741 main.py:230 INFO] Detected system ID: KnownSystem.ocejon
[2024-04-10 21:43:51,882 harness.py:236 INFO] The harness will load 1 plugins: ['build/plugins/RNNTOptPlugin/librnntoptplugin.so']
[2024-04-10 21:43:51,898 generate_conf_files.py:107 INFO] Generated measurements/ entries for ocejon_TRT/rnnt/SingleStream
[2024-04-10 21:43:51,898 __init__.py:46 INFO] Running command: ./build/bin/harness_rnnt --plugins="build/plugins/RNNTOptPlugin/librnntoptplugin.so" --logfile_outdir="/work/build/logs/2024.04.10-21.42.59/ocejon_TRT/rnnt/SingleStream" --logfile_prefix="mlperf_log_" --performance_sample_count=2513 --audio_batch_size=1 --audio_buffer_num_lines=1 --audio_fp16_input=true --dali_batches_issue_ahead=1 --dali_pipeline_depth=1 --disable_encoder_plugin=true --num_warmups=32 --mlperf_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/SingleStream/mlperf.conf" --user_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/SingleStream/user.conf" --batch_size=1 --cuda_graph=true --pipelined_execution=true --batch_sorting=false --enable_audio_processing=true --use_copy_kernel=true --streams_per_gpu=1 --start_from_device=false --audio_serialized_pipeline_file="build/bin/dali/dali_pipeline_gpu_fp16.pth" --scenario SingleStream --model rnnt --engine_dir="./build/engines/ocejon/rnnt/SingleStream"
[2024-04-10 21:43:51,898 __init__.py:53 INFO] Overriding Environment
audio_batch_size : 1
audio_buffer_num_lines : 1
audio_fp16_input : True
benchmark : Benchmark.RNNT
buffer_manager_thread_count : 0
dali_batches_issue_ahead : 1
dali_pipeline_depth : 1
data_dir : /scratch/gonisla//data
disable_encoder_plugin : True
gpu_batch_size : 1
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : fp16
input_format : linear
log_dir : /work/build/logs/2024.04.10-21.42.59
map_path : data_maps/rnnt_dev_clean_512/val_map.txt
nobatch_sorting : True
nouse_copy_kernel : False
num_warmups : 32
precision : fp16
preprocessed_data_dir : /scratch/gonisla//preprocessed_data
scenario : Scenario.SingleStream
single_stream_expected_latency_ns : 1500000
single_stream_target_latency_percentile : 99.0
system : SystemConfiguration(host_cpu_conf=CPUConfiguration(layout={CPU(name='Intel(R) Xeon(R) Silver 4314 CPU @ 2.40GHz', architecture=<CPUArchitecture.x86_64: AliasedName(name='x86_64', aliases=(), patterns=())>, core_count=16, threads_per_core=1): 1}), host_mem_conf=MemoryConfiguration(host_memory_capacity=Memory(quantity=65.551536, byte_suffix=<ByteSuffix.GB: (1000, 3)>, _num_bytes=65551536000), comparison_tolerance=0.05), accelerator_conf=AcceleratorConfiguration(layout=defaultdict(<class 'int'>, {GPU(name='NVIDIA A30', accelerator_type=<AcceleratorType.Discrete: AliasedName(name='Discrete', aliases=(), patterns=())>, vram=Memory(quantity=24.0, byte_suffix=<ByteSuffix.GiB: (1024, 3)>, _num_bytes=25769803776), max_power_limit=165.0, pci_id='0x20B710DE', compute_sm=80): 1})), numa_conf=None, system_id='ocejon')
tensor_path : build/preprocessed_data/rnnt_dev_clean_512/fp16
use_graphs : True
system_id : ocejon
config_name : ocejon_rnnt_SingleStream
workload_setting : WorkloadSetting(HarnessType.Custom, AccuracyTarget.k_99, PowerSetting.MaxP)
optimization_level : plugin-enabled
use_cpu : False
use_inferentia : False
num_profiles : 1
config_ver : custom_k_99_MaxP
accuracy_level : 99%
inference_server : custom
skip_file_checks : False
power_limit : None
cpu_freq : None
&&&& RUNNING RNN-T_Harness # ./build/bin/harness_rnnt
I0410 21:43:51.958928  4101 main_rnnt.cc:2903] Found 1 GPUs
[I] Starting creating QSL.
[I] Finished creating QSL.
[I] Starting creating SUT.
[I] Set to device 0
Dali pipeline creating..
Dali pipeline created
[I] Creating stream 0/1
[I] [TRT] Loaded engine size: 81 MiB
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +8, GPU +12, now: CPU 128, GPU 644 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +81, now: CPU 0, GPU 81 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 128, GPU 644 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +58, now: CPU 0, GPU 139 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntEncoder runner: encoder
[I] [TRT] Loaded engine size: 3 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 53, GPU 710 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 53, GPU 720 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 139 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 53, GPU 724 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 53, GPU 732 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 139 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntDecoder runner: decoder
[I] [TRT] Loaded engine size: 1 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +1, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointFc1 runner: fc1_a
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointFc1 runner: fc1_b
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointBackend runner: joint_backend
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 55, GPU 742 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +12, now: CPU 55, GPU 754 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 55, GPU 746 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 55, GPU 754 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntIsel runner: isel
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntIgather runner: igather
[I] Instantiated RnntEngineContainer runner
cudaMemcpy blocking 
cudaMemcpy blocking 
[I] Instantiated RnntTensorContainer host memory
Stream::Stream sampleSize: 61440
Stream::Stream singleSampleSize: 480
Stream::Stream fullseqSampleSize: 61440
Stream::Stream mBatchSize: 1
[I] Finished creating SUT.
[I] Starting warming up SUT.
[I] Finished warming up SUT.
[I] Starting running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : RNNT SERVER
Scenario : SingleStream
Mode     : PerformanceOnly
99th percentile latency (ns) : 30461854
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes
Early Stopping Result:
 * Processed at least 662 queries (39976).
 * Would discard 352 highest latency queries.
 * Early stopping 99th percentile estimate: 30637682
 * Early stopping 99th percentile estimate: 30637682

================================================
Additional Stats
================================================
QPS w/ loadgen overhead         : 66.62
QPS w/o loadgen overhead        : 66.87

Min latency (ns)                : 3885127
Max latency (ns)                : 34858422
Mean latency (ns)               : 14953509
50.00 percentile latency (ns)   : 13836317
90.00 percentile latency (ns)   : 23770050
95.00 percentile latency (ns)   : 26821459
97.00 percentile latency (ns)   : 28460430
99.00 percentile latency (ns)   : 30461854
99.90 percentile latency (ns)   : 32092321

================================================
Test Parameters Used
================================================
samples_per_query : 1
target_qps : 666.667
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 100
max_query_count : 0
qsl_rng_seed : 148687905518835231
sample_index_rng_seed : 520418551913322573
schedule_rng_seed : 811580660758947900
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
accuracy_log_sampling_target : 0
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 2513

No warnings encountered during test.

No errors encountered during test.
[I] Finished running actual test.
&&&& PASSED RNN-T_Harness # ./build/bin/harness_rnnt
[2024-04-10 21:53:56,623 run_harness.py:167 INFO] Result: result_90.00_percentile_latency_ns: 23770050, Result is VALID
 
======================== Result summaries: ========================

 ocejon_TRT-custom_k_99_MaxP-SingleStream:
   rnnt:
     performance: result_90.00_percentile_latency_ns: 23770050, Result is VALID
 

======================== Extra Perf Stats: ========================

 ocejon_TRT-custom_k_99_MaxP-SingleStream:
    FileNotFoundError: Cannot find perf logs for ocejon_TRT/rnnt/SingleStream at build/artifacts/closed/NVIDIA/results/ocejon_TRT/rnnt/SingleStream/performance/run_1. Non-NVIDIA users ignore this. NVIDIA users run `make pull_artifacts_repo`.
make[1]: Leaving directory '/work'
