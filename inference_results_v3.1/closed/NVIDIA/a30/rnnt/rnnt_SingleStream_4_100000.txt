$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
make[1]: Entering directory '/work'
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
[05/19/2024-13:38:25] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 126, GPU 480 (MiB)
[05/19/2024-13:38:32] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1957, GPU +346, now: CPU 2188, GPU 826 (MiB)
[05/19/2024-13:38:33] [TRT] [I] Graph optimization time: 0.000334912 seconds.
[05/19/2024-13:38:33] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +10, now: CPU 2532, GPU 836 (MiB)
[05/19/2024-13:38:33] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2533, GPU 846 (MiB)
[05/19/2024-13:38:33] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/19/2024-13:38:34] [TRT] [I] Detected 6 inputs and 5 output network tensors.
[05/19/2024-13:38:34] [TRT] [I] Total Host Persistent Memory: 3648
[05/19/2024-13:38:34] [TRT] [I] Total Device Persistent Memory: 4096
[05/19/2024-13:38:34] [TRT] [I] Total Scratch Memory: 59700512
[05/19/2024-13:38:34] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 7 steps to complete.
[05/19/2024-13:38:34] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.027343ms to assign 4 blocks to 7 nodes requiring 59963904 bytes.
[05/19/2024-13:38:34] [TRT] [I] Total Activation Memory: 59963392
[05/19/2024-13:38:34] [TRT] [I] Total Weights Memory: 85935104
[05/19/2024-13:38:34] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2863, GPU 946 (MiB)
[05/19/2024-13:38:34] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[05/19/2024-13:38:34] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[05/19/2024-13:38:34] [TRT] [W] Check verbose logs for the list of affected weights.
[05/19/2024-13:38:34] [TRT] [W] - 9 weights are affected by this issue: Detected subnormal FP16 values.
[05/19/2024-13:38:34] [TRT] [W] - 5 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.
[05/19/2024-13:38:34] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[05/19/2024-13:38:34] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +81, GPU +82, now: CPU 81, GPU 82 (MiB)
[05/19/2024-13:38:34] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2781, GPU 838 (MiB)
[05/19/2024-13:38:35] [TRT] [I] Graph optimization time: 0.000239986 seconds.
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2787, GPU 848 (MiB)
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2787, GPU 856 (MiB)
[05/19/2024-13:38:35] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/19/2024-13:38:35] [TRT] [I] Detected 3 inputs and 3 output network tensors.
[05/19/2024-13:38:35] [TRT] [I] Total Host Persistent Memory: 368
[05/19/2024-13:38:35] [TRT] [I] Total Device Persistent Memory: 0
[05/19/2024-13:38:35] [TRT] [I] Total Scratch Memory: 8960
[05/19/2024-13:38:35] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 2 steps to complete.
[05/19/2024-13:38:35] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.005325ms to assign 2 blocks to 2 nodes requiring 10240 bytes.
[05/19/2024-13:38:35] [TRT] [I] Total Activation Memory: 10240
[05/19/2024-13:38:35] [TRT] [I] Total Weights Memory: 18584
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2797, GPU 868 (MiB)
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2797, GPU 876 (MiB)
[05/19/2024-13:38:35] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[05/19/2024-13:38:35] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2796, GPU 840 (MiB)
[05/19/2024-13:38:35] [TRT] [I] Graph optimization time: 0.000188777 seconds.
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2797, GPU 850 (MiB)
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2797, GPU 858 (MiB)
[05/19/2024-13:38:35] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/19/2024-13:38:35] [TRT] [I] Detected 7 inputs and 3 output network tensors.
[05/19/2024-13:38:35] [TRT] [I] Total Host Persistent Memory: 560
[05/19/2024-13:38:35] [TRT] [I] Total Device Persistent Memory: 0
[05/19/2024-13:38:35] [TRT] [I] Total Scratch Memory: 0
[05/19/2024-13:38:35] [TRT] [I] Total Activation Memory: 0
[05/19/2024-13:38:35] [TRT] [I] Total Weights Memory: 0
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2797, GPU 866 (MiB)
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2797, GPU 874 (MiB)
[05/19/2024-13:38:35] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[05/19/2024-13:38:35] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2796, GPU 840 (MiB)
[05/19/2024-13:38:35] [TRT] [I] Graph optimization time: 0.000138699 seconds.
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2797, GPU 850 (MiB)
[05/19/2024-13:38:35] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2797, GPU 858 (MiB)
[05/19/2024-13:38:35] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/19/2024-13:38:36] [TRT] [I] Detected 2 inputs and 1 output network tensors.
[05/19/2024-13:38:36] [TRT] [I] Total Host Persistent Memory: 32
[05/19/2024-13:38:36] [TRT] [I] Total Device Persistent Memory: 0
[05/19/2024-13:38:36] [TRT] [I] Total Scratch Memory: 0
[05/19/2024-13:38:36] [TRT] [I] Total Activation Memory: 0
[05/19/2024-13:38:36] [TRT] [I] Total Weights Memory: 8
[05/19/2024-13:38:36] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[05/19/2024-13:38:36] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[05/19/2024-13:38:36] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/19/2024-13:38:36] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2797, GPU 840 (MiB)
[05/19/2024-13:38:37] [TRT] [I] Graph optimization time: 0.000110428 seconds.
[05/19/2024-13:38:37] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2799, GPU 850 (MiB)
[05/19/2024-13:38:37] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2799, GPU 858 (MiB)
[05/19/2024-13:38:37] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/19/2024-13:38:39] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[05/19/2024-13:38:39] [TRT] [I] Total Host Persistent Memory: 7328
[05/19/2024-13:38:39] [TRT] [I] Total Device Persistent Memory: 0
[05/19/2024-13:38:39] [TRT] [I] Total Scratch Memory: 0
[05/19/2024-13:38:39] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 2 steps to complete.
[05/19/2024-13:38:39] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.004073ms to assign 2 blocks to 2 nodes requiring 1024 bytes.
[05/19/2024-13:38:39] [TRT] [I] Total Activation Memory: 1024
[05/19/2024-13:38:39] [TRT] [I] Total Weights Memory: 1049600
[05/19/2024-13:38:39] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[05/19/2024-13:38:39] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +2, now: CPU 0, GPU 2 (MiB)
[05/19/2024-13:38:39] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/19/2024-13:38:39] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2903, GPU 840 (MiB)
[05/19/2024-13:38:39] [TRT] [I] Graph optimization time: 8.4185e-05 seconds.
[05/19/2024-13:38:39] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2904, GPU 850 (MiB)
[05/19/2024-13:38:39] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2904, GPU 858 (MiB)
[05/19/2024-13:38:39] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/19/2024-13:38:40] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[05/19/2024-13:38:40] [TRT] [I] Total Host Persistent Memory: 7328
[05/19/2024-13:38:40] [TRT] [I] Total Device Persistent Memory: 0
[05/19/2024-13:38:40] [TRT] [I] Total Scratch Memory: 0
[05/19/2024-13:38:40] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 2 steps to complete.
[05/19/2024-13:38:40] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.004105ms to assign 2 blocks to 2 nodes requiring 1024 bytes.
[05/19/2024-13:38:40] [TRT] [I] Total Activation Memory: 1024
[05/19/2024-13:38:40] [TRT] [I] Total Weights Memory: 327680
[05/19/2024-13:38:40] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[05/19/2024-13:38:40] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[05/19/2024-13:38:40] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/19/2024-13:38:40] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2903, GPU 840 (MiB)
[05/19/2024-13:38:40] [TRT] [I] Graph optimization time: 0.000246455 seconds.
[05/19/2024-13:38:40] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +10, now: CPU 2904, GPU 850 (MiB)
[05/19/2024-13:38:40] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2904, GPU 858 (MiB)
[05/19/2024-13:38:40] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/19/2024-13:38:49] [TRT] [I] Detected 2 inputs and 1 output network tensors.
[05/19/2024-13:38:49] [TRT] [I] Total Host Persistent Memory: 7680
[05/19/2024-13:38:49] [TRT] [I] Total Device Persistent Memory: 0
[05/19/2024-13:38:49] [TRT] [I] Total Scratch Memory: 32
[05/19/2024-13:38:49] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 5 steps to complete.
[05/19/2024-13:38:49] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.010801ms to assign 3 blocks to 5 nodes requiring 2048 bytes.
[05/19/2024-13:38:49] [TRT] [I] Total Activation Memory: 2048
[05/19/2024-13:38:49] [TRT] [I] Total Weights Memory: 29754
[05/19/2024-13:38:49] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 138 MiB, GPU 227 MiB
[05/19/2024-13:38:49] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[05/19/2024-13:38:49] [TRT] [I] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
Loading TensorRT plugin from build/plugins/RNNTOptPlugin/librnntoptplugin.so
Initializing DALI with parameters:
	        __class__ : <class 'code.rnnt.dali.pipeline.DALIInferencePipeline'>
	 audio_fp16_input : True
	       batch_size : 16
	           device : gpu
	        device_id : 0
	           dither : 1e-05
	   frame_splicing : 3
	         highfreq : 0
	              log : True
	          lowfreq : 0
	     max_duration : 16.7
	            n_fft : 512
	            nfilt : 80
	        normalize : per_feature
	      num_threads : 2
	           pad_to : 8
	          preemph : 0.97
	processing_layout : tf
	   resample_range : None
	      sample_rate : 16000
	             self : <code.rnnt.dali.pipeline.DALIInferencePipeline object at 0x7fa6631e7520>
	    total_samples : 16
	           window : hann
	      window_size : 0.02
	    window_stride : 0.01
self.n_fft = 512
self.hop_length = 160
self.win_length = 320
self.window_tensor = tensor([0.0000e+00, 9.6977e-05, 3.8791e-04, 8.7264e-04, 1.5510e-03, 2.4227e-03,
        3.4875e-03, 4.7449e-03, 6.1944e-03, 7.8355e-03, 9.6675e-03, 1.1690e-02,
        1.3901e-02, 1.6302e-02, 1.8890e-02, 2.1664e-02, 2.4624e-02, 2.7769e-02,
        3.1096e-02, 3.4606e-02, 3.8296e-02, 4.2165e-02, 4.6212e-02, 5.0435e-02,
        5.4833e-02, 5.9403e-02, 6.4144e-02, 6.9054e-02, 7.4131e-02, 7.9373e-02,
        8.4779e-02, 9.0346e-02, 9.6071e-02, 1.0195e-01, 1.0799e-01, 1.1418e-01,
        1.2052e-01, 1.2700e-01, 1.3363e-01, 1.4041e-01, 1.4732e-01, 1.5437e-01,
        1.6155e-01, 1.6886e-01, 1.7631e-01, 1.8388e-01, 1.9157e-01, 1.9938e-01,
        2.0730e-01, 2.1534e-01, 2.2350e-01, 2.3175e-01, 2.4012e-01, 2.4858e-01,
        2.5714e-01, 2.6580e-01, 2.7454e-01, 2.8338e-01, 2.9229e-01, 3.0129e-01,
        3.1037e-01, 3.1951e-01, 3.2873e-01, 3.3802e-01, 3.4737e-01, 3.5677e-01,
        3.6624e-01, 3.7575e-01, 3.8531e-01, 3.9492e-01, 4.0457e-01, 4.1425e-01,
        4.2397e-01, 4.3372e-01, 4.4349e-01, 4.5329e-01, 4.6310e-01, 4.7293e-01,
        4.8277e-01, 4.9261e-01, 5.0246e-01, 5.1231e-01, 5.2215e-01, 5.3198e-01,
        5.4181e-01, 5.5161e-01, 5.6140e-01, 5.7116e-01, 5.8089e-01, 5.9059e-01,
        6.0026e-01, 6.0989e-01, 6.1947e-01, 6.2901e-01, 6.3850e-01, 6.4794e-01,
        6.5732e-01, 6.6663e-01, 6.7588e-01, 6.8507e-01, 6.9418e-01, 7.0322e-01,
        7.1218e-01, 7.2105e-01, 7.2984e-01, 7.3854e-01, 7.4715e-01, 7.5566e-01,
        7.6408e-01, 7.7239e-01, 7.8059e-01, 7.8869e-01, 7.9667e-01, 8.0454e-01,
        8.1229e-01, 8.1992e-01, 8.2743e-01, 8.3481e-01, 8.4206e-01, 8.4917e-01,
        8.5616e-01, 8.6300e-01, 8.6970e-01, 8.7626e-01, 8.8267e-01, 8.8893e-01,
        8.9505e-01, 9.0101e-01, 9.0681e-01, 9.1246e-01, 9.1794e-01, 9.2327e-01,
        9.2843e-01, 9.3342e-01, 9.3825e-01, 9.4290e-01, 9.4739e-01, 9.5170e-01,
        9.5583e-01, 9.5979e-01, 9.6357e-01, 9.6717e-01, 9.7059e-01, 9.7383e-01,
        9.7688e-01, 9.7975e-01, 9.8243e-01, 9.8492e-01, 9.8723e-01, 9.8935e-01,
        9.9127e-01, 9.9301e-01, 9.9455e-01, 9.9591e-01, 9.9707e-01, 9.9804e-01,
        9.9881e-01, 9.9939e-01, 9.9978e-01, 9.9998e-01, 9.9998e-01, 9.9978e-01,
        9.9939e-01, 9.9881e-01, 9.9804e-01, 9.9707e-01, 9.9591e-01, 9.9455e-01,
        9.9301e-01, 9.9127e-01, 9.8935e-01, 9.8723e-01, 9.8492e-01, 9.8243e-01,
        9.7975e-01, 9.7688e-01, 9.7383e-01, 9.7059e-01, 9.6717e-01, 9.6357e-01,
        9.5979e-01, 9.5583e-01, 9.5170e-01, 9.4739e-01, 9.4290e-01, 9.3825e-01,
        9.3342e-01, 9.2843e-01, 9.2327e-01, 9.1794e-01, 9.1246e-01, 9.0681e-01,
        9.0101e-01, 8.9505e-01, 8.8893e-01, 8.8267e-01, 8.7626e-01, 8.6970e-01,
        8.6300e-01, 8.5616e-01, 8.4917e-01, 8.4206e-01, 8.3481e-01, 8.2743e-01,
        8.1992e-01, 8.1229e-01, 8.0454e-01, 7.9667e-01, 7.8869e-01, 7.8059e-01,
        7.7239e-01, 7.6408e-01, 7.5566e-01, 7.4715e-01, 7.3854e-01, 7.2984e-01,
        7.2105e-01, 7.1218e-01, 7.0322e-01, 6.9418e-01, 6.8507e-01, 6.7589e-01,
        6.6663e-01, 6.5732e-01, 6.4794e-01, 6.3850e-01, 6.2901e-01, 6.1947e-01,
        6.0989e-01, 6.0026e-01, 5.9059e-01, 5.8089e-01, 5.7116e-01, 5.6140e-01,
        5.5161e-01, 5.4181e-01, 5.3198e-01, 5.2215e-01, 5.1231e-01, 5.0246e-01,
        4.9261e-01, 4.8277e-01, 4.7293e-01, 4.6310e-01, 4.5329e-01, 4.4349e-01,
        4.3372e-01, 4.2397e-01, 4.1425e-01, 4.0457e-01, 3.9492e-01, 3.8531e-01,
        3.7575e-01, 3.6624e-01, 3.5677e-01, 3.4737e-01, 3.3802e-01, 3.2873e-01,
        3.1951e-01, 3.1037e-01, 3.0129e-01, 2.9229e-01, 2.8338e-01, 2.7454e-01,
        2.6580e-01, 2.5714e-01, 2.4858e-01, 2.4012e-01, 2.3175e-01, 2.2350e-01,
        2.1534e-01, 2.0730e-01, 1.9938e-01, 1.9157e-01, 1.8388e-01, 1.7631e-01,
        1.6886e-01, 1.6155e-01, 1.5437e-01, 1.4732e-01, 1.4041e-01, 1.3363e-01,
        1.2700e-01, 1.2052e-01, 1.1418e-01, 1.0799e-01, 1.0195e-01, 9.6071e-02,
        9.0346e-02, 8.4779e-02, 7.9373e-02, 7.4131e-02, 6.9054e-02, 6.4144e-02,
        5.9403e-02, 5.4833e-02, 5.0435e-02, 4.6212e-02, 4.2165e-02, 3.8296e-02,
        3.4606e-02, 3.1096e-02, 2.7769e-02, 2.4624e-02, 2.1664e-02, 1.8889e-02,
        1.6302e-02, 1.3901e-02, 1.1690e-02, 9.6675e-03, 7.8355e-03, 6.1944e-03,
        4.7449e-03, 3.4875e-03, 2.4227e-03, 1.5510e-03, 8.7264e-04, 3.8791e-04,
        9.6977e-05, 2.9802e-08])
self.sample_rate = 16000
self.window_size = 0.02
self.window_stride = 0.01
self.lowfreq = 0
self.device = gpu
Time taken to generate engines: 25.614153623580933 seconds
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
$ARCH is [x86_64]
$SYSTEM_NAME is [KnownSystem.ocejon]
$IS_SOC is [0]
$USE_CPU is [0]
$USE_INFERENTIA is [0]
[2024-05-19 13:39:02,896 main.py:230 INFO] Detected system ID: KnownSystem.ocejon
[2024-05-19 13:39:03,036 harness.py:236 INFO] The harness will load 1 plugins: ['build/plugins/RNNTOptPlugin/librnntoptplugin.so']
[2024-05-19 13:39:03,051 generate_conf_files.py:107 INFO] Generated measurements/ entries for ocejon_TRT/rnnt/SingleStream
[2024-05-19 13:39:03,052 __init__.py:46 INFO] Running command: ./build/bin/harness_rnnt --plugins="build/plugins/RNNTOptPlugin/librnntoptplugin.so" --logfile_outdir="/work/build/logs/2024.05.19-13.38.10/ocejon_TRT/rnnt/SingleStream" --logfile_prefix="mlperf_log_" --performance_sample_count=2513 --audio_batch_size=1 --audio_buffer_num_lines=1 --audio_fp16_input=true --dali_batches_issue_ahead=1 --dali_pipeline_depth=1 --disable_encoder_plugin=true --num_warmups=32 --mlperf_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/SingleStream/mlperf.conf" --user_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/SingleStream/user.conf" --batch_size=4 --cuda_graph=true --pipelined_execution=true --batch_sorting=false --enable_audio_processing=true --use_copy_kernel=true --streams_per_gpu=1 --start_from_device=false --audio_serialized_pipeline_file="build/bin/dali/dali_pipeline_gpu_fp16.pth" --scenario SingleStream --model rnnt --engine_dir="./build/engines/ocejon/rnnt/SingleStream"
[2024-05-19 13:39:03,052 __init__.py:53 INFO] Overriding Environment
audio_batch_size : 1
audio_buffer_num_lines : 1
audio_fp16_input : True
benchmark : Benchmark.RNNT
buffer_manager_thread_count : 0
dali_batches_issue_ahead : 1
dali_pipeline_depth : 1
data_dir : /scratch/gonisla//data
disable_encoder_plugin : True
gpu_batch_size : 4
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : fp16
input_format : linear
log_dir : /work/build/logs/2024.05.19-13.38.10
map_path : data_maps/rnnt_dev_clean_512/val_map.txt
nobatch_sorting : True
nouse_copy_kernel : False
num_warmups : 32
precision : fp16
preprocessed_data_dir : /scratch/gonisla//preprocessed_data
scenario : Scenario.SingleStream
single_stream_expected_latency_ns : 100000
single_stream_target_latency_percentile : 99.0
system : SystemConfiguration(host_cpu_conf=CPUConfiguration(layout={CPU(name='Intel(R) Xeon(R) Silver 4314 CPU @ 2.40GHz', architecture=<CPUArchitecture.x86_64: AliasedName(name='x86_64', aliases=(), patterns=())>, core_count=16, threads_per_core=1): 1}), host_mem_conf=MemoryConfiguration(host_memory_capacity=Memory(quantity=65.551536, byte_suffix=<ByteSuffix.GB: (1000, 3)>, _num_bytes=65551536000), comparison_tolerance=0.05), accelerator_conf=AcceleratorConfiguration(layout=defaultdict(<class 'int'>, {GPU(name='NVIDIA A30', accelerator_type=<AcceleratorType.Discrete: AliasedName(name='Discrete', aliases=(), patterns=())>, vram=Memory(quantity=24.0, byte_suffix=<ByteSuffix.GiB: (1024, 3)>, _num_bytes=25769803776), max_power_limit=165.0, pci_id='0x20B710DE', compute_sm=80): 1})), numa_conf=None, system_id='ocejon')
tensor_path : build/preprocessed_data/rnnt_dev_clean_512/fp16
use_graphs : True
system_id : ocejon
config_name : ocejon_rnnt_SingleStream
workload_setting : WorkloadSetting(HarnessType.Custom, AccuracyTarget.k_99, PowerSetting.MaxP)
optimization_level : plugin-enabled
use_cpu : False
use_inferentia : False
num_profiles : 1
config_ver : custom_k_99_MaxP
accuracy_level : 99%
inference_server : custom
skip_file_checks : False
power_limit : None
cpu_freq : None
<class 'ctypes.CDLL'>
<_FuncPtr object at 0x7f75fe9efc40>
server_ip b''
port 0
server_ip b'127.0.0.1'
port 6526
&&&& RUNNING RNN-T_Harness # ./build/bin/harness_rnnt
I0519 13:39:03.112525 276533 main_rnnt.cc:2903] Found 1 GPUs
[I] Starting creating QSL.
[I] Finished creating QSL.
[I] Starting creating SUT.
[I] Set to device 0
Dali pipeline creating..
Dali pipeline created
[I] Creating stream 0/1
[I] [TRT] Loaded engine size: 81 MiB
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +8, GPU +12, now: CPU 128, GPU 644 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +81, now: CPU 0, GPU 81 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 128, GPU 644 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +58, now: CPU 0, GPU 139 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntEncoder runner: encoder
[I] [TRT] Loaded engine size: 3 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 53, GPU 710 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 53, GPU 720 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 139 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 53, GPU 724 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 53, GPU 732 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 139 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntDecoder runner: decoder
[I] [TRT] Loaded engine size: 1 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +1, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointFc1 runner: fc1_a
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointFc1 runner: fc1_b
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntJointBackend runner: joint_backend
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +8, now: CPU 55, GPU 742 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +12, now: CPU 55, GPU 754 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 55, GPU 746 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 55, GPU 754 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntIsel runner: isel
[I] [TRT] Loaded engine size: 0 MiB
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 140 (MiB)
[E] [TRT] 3: [runtime.cpp::~Runtime::399] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::399, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
)
[I] Created RnntIgather runner: igather
[I] Instantiated RnntEngineContainer runner
cudaMemcpy blocking 
cudaMemcpy blocking 
[I] Instantiated RnntTensorContainer host memory
Stream::Stream sampleSize: 61440
Stream::Stream singleSampleSize: 480
Stream::Stream fullseqSampleSize: 61440
Stream::Stream mBatchSize: 4
[E] [TRT] 3: [executionContext.cpp::validateInputBindings::2042] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::validateInputBindings::2042, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [2,1] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 1, minimum dimension in profile is 1, but supplied dimension is 2.
)
F0519 13:39:04.529822 276533 main_rnnt.cc:809] Check failed: context->setBindingDimensions(bindingIdx, inputDims) == true (0 vs. 1) 
*** Check failure stack trace: ***
    @     0x7fb386432f00  google::LogMessage::Fail()
    @     0x7fb386432e3b  google::LogMessage::SendToLog()
    @     0x7fb38643276c  google::LogMessage::Flush()
    @     0x7fb386435d7a  google::LogMessageFatal::~LogMessageFatal()
    @     0x559882606220  EngineRunner::enqueue()
    @     0x5598825eabed  doBatchDecoderIteration()
    @     0x5598825eb4f4  makeDecoderGraph()
    @     0x5598825eea64  Stream::Stream()
    @     0x5598825f01f1  RNNTServer::RNNTServer()
    @     0x5598825e5dd1  main
    @     0x7fb36ce25083  __libc_start_main
    @     0x5598825e6b7e  _start
    @              (nil)  (unknown)
Aborted (core dumped)
127.0.0.1, 127.0.0.1, 9
6526
- > NVMLDevice
Agg. - > 0
Int. - > 0
Lines - > @
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
Lines - >  
- > 127.0.0.1
- > 6526
Traceback (most recent call last):
  File "/usr/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work/code/main.py", line 232, in <module>
    main(main_args, DETECTED_SYSTEM)
  File "/work/code/main.py", line 145, in main
    dispatch_action(main_args, config_dict, workload_setting)
  File "/work/code/main.py", line 203, in dispatch_action
    handler.run()
  File "/work/code/actionhandler/base.py", line 82, in run
    self.handle_failure()
  File "/work/code/actionhandler/run_harness.py", line 373, in handle_failure
    raise RuntimeError("Run harness failed!")
RuntimeError: Run harness failed!
Traceback (most recent call last):
  File "/work/code/actionhandler/run_harness.py", line 272, in handle
    result_data = self.harness.run_harness(flag_dict=self.harness_flag_dict, skip_generate_measurements=True)
  File "/work/code/common/harness.py", line 339, in run_harness
    output = run_command(self._construct_terminal_command(argstr), get_output=True, custom_env=self.env_vars)
  File "/work/code/common/__init__.py", line 67, in run_command
    raise subprocess.CalledProcessError(ret, cmd)
subprocess.CalledProcessError: Command './build/bin/harness_rnnt --plugins="build/plugins/RNNTOptPlugin/librnntoptplugin.so" --logfile_outdir="/work/build/logs/2024.05.19-13.38.10/ocejon_TRT/rnnt/SingleStream" --logfile_prefix="mlperf_log_" --performance_sample_count=2513 --audio_batch_size=1 --audio_buffer_num_lines=1 --audio_fp16_input=true --dali_batches_issue_ahead=1 --dali_pipeline_depth=1 --disable_encoder_plugin=true --num_warmups=32 --mlperf_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/SingleStream/mlperf.conf" --user_conf_path="build/loadgen-configs/ocejon_TRT/rnnt/SingleStream/user.conf" --batch_size=4 --cuda_graph=true --pipelined_execution=true --batch_sorting=false --enable_audio_processing=true --use_copy_kernel=true --streams_per_gpu=1 --start_from_device=false --audio_serialized_pipeline_file="build/bin/dali/dali_pipeline_gpu_fp16.pth" --scenario SingleStream --model rnnt --engine_dir="./build/engines/ocejon/rnnt/SingleStream"' returned non-zero exit status 134.
make[1]: Leaving directory '/work'
